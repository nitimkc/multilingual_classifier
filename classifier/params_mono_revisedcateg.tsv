lang	split	n_labels	max_len	model_checkpoint	epochs	batch_size	learning_rate
en	0.6,0.2,0.2	2	128	bert-base-uncased	6	16	0.00005
en	0.6,0.2,0.2	2	128	roberta-base	6	16	0.00005
en	0.6,0.2,0.2	2	128	vinai/bertweet-base	6	16	0.00005
en	0.6,0.2,0.2	2	128	vinai/bertweet-covid19-base-uncased	6	16	0.00005
en	0.6,0.2,0.2	2	128	digitalepidemiologylab/covid-twitter-bert-v2	6	16	0.00005
fr	0.6,0.2,0.2	2	128	camembert-base	6	16	0.00005
fr	0.6,0.2,0.2	2	128	camembert-large	6	16	0.00005
fr	0.6,0.2,0.2	2	128	dbmdz/bert-base-french-europeana-cased	6	16	0.00005
es	0.6,0.2,0.2	2	128	dccuchile/bert-base-spanish-wwm-uncased	6	16	0.00005
es	0.6,0.2,0.2	2	128	mrm8488/electricidad-base-discriminator	6	16	0.00005
es	0.6,0.2,0.2	2	128	bertin-project/bertin-roberta-base-spanish	6	16	0.00005
it	0.6,0.2,0.2	2	128	dbmdz/bert-base-italian-uncased	6	16	0.00005
it	0.6,0.2,0.2	2	128	osiria/bert-base-italian-uncased	6	16	0.00005
de	0.6,0.2,0.2	2	128	dbmdz/bert-base-german-uncased	6	16	0.00005
de	0.6,0.2,0.2	2	128	smanjil/German-MedBERT	6	16	0.00005
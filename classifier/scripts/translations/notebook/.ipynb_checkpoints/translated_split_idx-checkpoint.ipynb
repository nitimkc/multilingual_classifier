{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd4be8e8-2f4f-4be1-8322-c70326fc753b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54219e69-f34f-4337-aec6-aefecda48cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71337fa4-b6f3-49fd-8adf-e328f115a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = Path('/gaueko0/users/nmishra/multiling_fludetection/data')\n",
    "translated_dir = ROOT.joinpath('translated/revisedcateg')\n",
    "PARAMS_FILE = Path('/gaueko0/users/nmishra/multiling_fludetection/params_revisedcateg.tsv')\n",
    "OUT_PATH = Path('/gaueko0/users/nmishra/multiling_fludetection/evals/eval_revisedcateg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f023f25-9238-4873-b391-d0b4a8b60e3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4284, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all data\n",
    "all_data_revised = pd.read_csv(ROOT.joinpath('all').joinpath('alldata_revised.csv'))\n",
    "all_data_revised.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ee7fa35-dfad-4ed6-a85a-82070a1fe414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load splits for all data\n",
    "params = pd.read_csv(PARAMS_FILE, sep='\\t')\n",
    "SPLITS = params['split'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a84e23-62b5-451f-90f3-d6d32e8f528a",
   "metadata": {},
   "source": [
    "## Store translated data as one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "923b430b-8bfc-4d8c-a68a-a5976f57a204",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_type = 'one_to_many'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2620025f-1ab7-478a-9659-68745d6186a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21420, 6)\n"
     ]
    }
   ],
   "source": [
    "dir_path = translated_dir.joinpath(translation_type)\n",
    "all_files = [i for i in dir_path.glob(\"*.csv\")]\n",
    "translated_df = pd.concat([pd.read_csv(file) for file in all_files])\n",
    "translated_df.reset_index(inplace=True, drop=True)\n",
    "print(translated_df.shape)\n",
    "translated_df.to_csv(ROOT.joinpath('all').joinpath(f'all_{translation_type}_revisedcateg.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71aec6-a9ab-43d4-ae46-4013855f5309",
   "metadata": {},
   "source": [
    "## Get the ids associated with each split per language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10e06101-c86a-4e5f-abe6-9704d0553e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6,0.2,0.2\n",
      "Reading data split index from: /gaueko0/users/nmishra/multiling_fludetection/evals/eval_revisedcateg/testset0.6_0.2_0.2\n",
      "de train_idx\n",
      "[2101, 1787, 62, 2179, 1750]\n",
      "[1597797277451501568 1182462946317873153 1214186658020700160\n",
      " 1132278455377244160 1072053340866076672]\n",
      "de test_idx\n",
      "[379, 2155, 1948, 2031, 1858]\n",
      "[1632035048521101314 1078046643847659521 1050646360775507969\n",
      " 1289189394134441985 1358670154939338757]\n",
      "de valid_idx\n",
      "[329, 291, 331, 2325, 1977]\n",
      "[1476731020183543810 1327662484707299332 1356587864973316098\n",
      " 1631238122406133761 1081271631497101312]\n",
      "en train_idx\n",
      "[416, 449, 540, 445, 435]\n",
      "[1065631825840750592 1060956170981122049 1089985045316530176\n",
      " 1066849485198897152 1057296139299491840]\n",
      "en test_idx\n",
      "[529, 475, 503, 568, 512]\n",
      "[1115406640201621505 1046020176796364801 1103029957914230785\n",
      " 1095026877322878976 1106334001491521536]\n",
      "en valid_idx\n",
      "[487, 556, 421, 513, 557]\n",
      "[1084219395423911937 1093763112254226432 1050673056639680512\n",
      " 1083773686182805506 1121555076097748993]\n",
      "es train_idx\n",
      "[742, 650, 845, 2997, 3051]\n",
      "[1538618165105762306 1326987008066154497 1325194248325566467\n",
      " 1328226012942000128 1365781731224285192]\n",
      "es test_idx\n",
      "[2773, 2503, 2605, 2809, 2884]\n",
      "[1145023753405026305 1577388721661530112 1223103368198930434\n",
      " 1333786441818619904 1536409419558178816]\n",
      "es valid_idx\n",
      "[3016, 2955, 2738, 2371, 2543]\n",
      "[1377266273139187715 1111039509402140679 1096229902788055040\n",
      " 1158558807934607360 1173137241813725184]\n",
      "fr train_idx\n",
      "[3567, 3508, 3476, 3228, 1246]\n",
      "[ 653682962786091008  153057718578581504 1540410501133377536\n",
      " 1041320512926957568  811484535997272064]\n",
      "fr test_idx\n",
      "[3358, 1296, 1270, 1305, 3604]\n",
      "[ 301025159677100033 1110251830695612424  986659956005982208\n",
      " 1342904263492710401 1024690457769660417]\n",
      "fr valid_idx\n",
      "[3229, 1153, 3463, 1284, 3206]\n",
      "[ 966226887293984768 1609473034531880960 1379472976358350849\n",
      " 1093563528684933121  822750322175201280]\n",
      "it train_idx\n",
      "[1479, 1425, 4084, 4025, 1569]\n",
      "[1397711698526715907 1298933686713319424 1619380115351420928\n",
      " 1351783742218629121 1174056137429344256]\n",
      "it test_idx\n",
      "[1666, 4237, 4005, 3858, 4223]\n",
      "[1407673299769909251 1481370481227931652 1431224288338665478\n",
      " 1506277372613562378 1418944111487463430]\n",
      "it valid_idx\n",
      "[4068, 4037, 1713, 3906, 4074]\n",
      "[1544276603676524546 1537709444653621248 1581623348038991872\n",
      " 1110270539900309504 1617953382999928832]\n"
     ]
    }
   ],
   "source": [
    "# load original split index\n",
    "\n",
    "# for split in SPLITS:\n",
    "split = SPLITS[0]\n",
    "print(split)\n",
    "\n",
    "# read data split index\n",
    "dirname = f\"testset{split.replace(',','_')}\"\n",
    "split_path = OUT_PATH.joinpath(dirname)\n",
    "print(f\"Reading data split index from: {split_path}\")\n",
    "with open(split_path.joinpath('split_idx.json'), 'r') as f:\n",
    "    split_idx = json.load(f) \n",
    "\n",
    "# get associated ids\n",
    "split_id = {}\n",
    "for lang, splits_dict in split_idx.items():\n",
    "    lang_split_id = {}\n",
    "    for split_type, idx in splits_dict.items():\n",
    "        print(lang, split_type)\n",
    "        print(idx[:5])\n",
    "        sub_df = all_data_revised.iloc[idx]['id'].values\n",
    "        print(sub_df[:5])\n",
    "        lang_split_id[split_type] = all_data_revised.iloc[idx]['id'].values\n",
    "    split_id[lang] = lang_split_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7c3f8424-61ac-4606-8da8-7e1f060b61ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2610\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[742, 650, 845, 2997, 3051, 696, 2626, 2806, 2...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            de   en                                                 es   fr  \\\n",
       "train_idx  NaN  NaN  [742, 650, 845, 2997, 3051, 696, 2626, 2806, 2...  NaN   \n",
       "test_idx   NaN  NaN                                                NaN  NaN   \n",
       "valid_idx  NaN  NaN                                                NaN  NaN   \n",
       "\n",
       "            it  \n",
       "train_idx  NaN  \n",
       "test_idx   NaN  \n",
       "valid_idx  NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check each index is uniquely placed in one split type of one language only\n",
    "n = np.random.randint(0, all_data_revised.shape[0])\n",
    "print(n)\n",
    "test_df = pd.DataFrame.from_dict(split_idx)\n",
    "test_df[test_df.map(lambda x: n in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3394b68b-8863-46a4-b667-2ba5e5005cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1143333947004399617]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[1538618165105762306, 1326987008066154497, 132...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            de   en                                                 es   fr  \\\n",
       "train_idx  NaN  NaN  [1538618165105762306, 1326987008066154497, 132...  NaN   \n",
       "test_idx   NaN  NaN                                                NaN  NaN   \n",
       "valid_idx  NaN  NaN                                                NaN  NaN   \n",
       "\n",
       "            it  \n",
       "train_idx  NaN  \n",
       "test_idx   NaN  \n",
       "valid_idx  NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check each id is uniquely placed in one split type of one language only\n",
    "n = all_data_revised['id'].sample(n=1).values\n",
    "print(n)\n",
    "test_df = pd.DataFrame.from_dict(split_id)\n",
    "test_df[test_df.map(lambda x: n in x)]\n",
    "# test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e517a31-6cf4-4f89-be60-79811c611365",
   "metadata": {},
   "source": [
    "## Get subsequent index for these ids in the translated dataframe \n",
    "#### (for each split and each language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "219d4f78-a876-4890-a417-5c3b72fb2960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de train_idx\n",
      "  579.0\n",
      "de test_idx\n",
      "  194.0\n",
      "de valid_idx\n",
      "  194.0\n",
      "en train_idx\n",
      "  117.0\n",
      "en test_idx\n",
      "  40.0\n",
      "en valid_idx\n",
      "  39.0\n",
      "es train_idx\n",
      "  698.0\n",
      "es test_idx\n",
      "  233.0\n",
      "es valid_idx\n",
      "  233.0\n",
      "fr train_idx\n",
      "  576.0\n",
      "fr test_idx\n",
      "  193.0\n",
      "fr valid_idx\n",
      "  192.0\n",
      "it train_idx\n",
      "  597.0\n",
      "it test_idx\n",
      "  200.0\n",
      "it valid_idx\n",
      "  199.0\n"
     ]
    }
   ],
   "source": [
    "onetomany_split_idx = {}\n",
    "for lang, splits_dict in split_id.items():\n",
    "    onetomany_lang_split_idx = {}\n",
    "    for split_type, ids in splits_dict.items():                       # for each split in each language\n",
    "        print(lang, split_type)\n",
    "        sub_df = translated_df[translated_df['id'].isin(ids)]         # take only the id that exists in revised split_idx for that langauge\n",
    "        print(f'  {sub_df.shape[0]/5}')\n",
    "        # print(sub_df[['id','lang']].head())\n",
    "        onetomany_lang_split_idx[split_type] = sub_df.index.tolist()  # get the index of the selected ids and save into respective split\n",
    "    onetomany_split_idx[lang] = onetomany_lang_split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb8baf27-cffa-4d6b-960c-de3b50eaba10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7412\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5830, 5831, 5832, 5833, 5834, 5835, 5836, 583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            de   en   es   fr  \\\n",
       "train_idx  NaN  NaN  NaN  NaN   \n",
       "test_idx   NaN  NaN  NaN  NaN   \n",
       "valid_idx  NaN  NaN  NaN  NaN   \n",
       "\n",
       "                                                          it  \n",
       "train_idx  [5830, 5831, 5832, 5833, 5834, 5835, 5836, 583...  \n",
       "test_idx                                                 NaN  \n",
       "valid_idx                                                NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check each index is uniquely placed in one split type of one language only\n",
    "n = np.random.randint(0, translated_df.shape[0])\n",
    "print(n)\n",
    "test_df = pd.DataFrame.from_dict(onetomany_split_idx)\n",
    "test_df[test_df.map(lambda x: n in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9e12ef2-f44b-4d96-b4a2-b9f87485931a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/multiling_fludetection/evals/eval_revisedcateg/testset0.6_0.2_0.2/one_to_many_split_idx.json\n"
     ]
    }
   ],
   "source": [
    "# save the split index\n",
    "print(split_path.joinpath(f'{translation_type}_split_idx.json'))\n",
    "with open(split_path.joinpath(f'{translation_type}_split_idx.json'), 'w') as f:\n",
    "    json.dump(onetomany_split_idx, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08994eb2-000e-4fc1-bff2-5ca2ce235f0a",
   "metadata": {},
   "source": [
    "## Combine ids associated with each split for all languages\n",
    "- train, valid and test split for each language will be the train, valid and test split for all languages\n",
    "- because in one to many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a7d0f3-cc41-4c9f-810f-7e335bbc0fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "07ff3558-c714-4819-afb3-5843db7fadde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1597797277451501568,\n",
       " 1182462946317873153,\n",
       " 1214186658020700160,\n",
       " 1132278455377244160,\n",
       " 1072053340866076672,\n",
       " 1559210759783157762,\n",
       " 1137258336209002496,\n",
       " 1116070009174921217,\n",
       " 1417581177934958593,\n",
       " 1130751529441476608]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_split_ids = pd.DataFrame(split_id).apply(lambda row: row.tolist(), axis=1)\n",
    "all_split_ids = all_split_ids.apply(lambda row: [item for eachlist in row for item in eachlist])\n",
    "all_split_ids = all_split_ids.to_dict()\n",
    "all_split_ids['train_idx'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4d40ec78-9bec-470a-9928-188324bcb9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>final_annotation</th>\n",
       "      <th>tweet</th>\n",
       "      <th>lang</th>\n",
       "      <th>year</th>\n",
       "      <th>overlap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1058586475737047040</td>\n",
       "      <td>1. Likely ILI infection</td>\n",
       "      <td>@user Je ne suis pas sûr, Federer a eu une bon...</td>\n",
       "      <td>fr</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1058586475737047040</td>\n",
       "      <td>1. Likely ILI infection</td>\n",
       "      <td>@user I'm not sure, Federer has been having a ...</td>\n",
       "      <td>en</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1058586475737047040</td>\n",
       "      <td>1. Likely ILI infection</td>\n",
       "      <td>@user Non ne sono sicuro, Federer ha avuto una...</td>\n",
       "      <td>it</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1058586475737047040</td>\n",
       "      <td>1. Likely ILI infection</td>\n",
       "      <td>@user Ich bin mir nicht sicher, Federer hatte ...</td>\n",
       "      <td>de</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1058586475737047040</td>\n",
       "      <td>1. Likely ILI infection</td>\n",
       "      <td>@user No estoy seguro, Federer lleva buena sem...</td>\n",
       "      <td>es</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1050092005806751747</td>\n",
       "      <td>3. Not Related to ILI or COVID-19 Infection</td>\n",
       "      <td>Cette semaine, ils se font vacciner contre la ...</td>\n",
       "      <td>fr</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1050092005806751747</td>\n",
       "      <td>3. Not Related to ILI or COVID-19 Infection</td>\n",
       "      <td>This week they get a flu shot and Alba doesn't...</td>\n",
       "      <td>en</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1050092005806751747</td>\n",
       "      <td>3. Not Related to ILI or COVID-19 Infection</td>\n",
       "      <td>Questa settimana viene fatto un vaccino antinf...</td>\n",
       "      <td>it</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1050092005806751747</td>\n",
       "      <td>3. Not Related to ILI or COVID-19 Infection</td>\n",
       "      <td>Diese Woche bekommen sie eine Grippeimpfung un...</td>\n",
       "      <td>de</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1050092005806751747</td>\n",
       "      <td>3. Not Related to ILI or COVID-19 Infection</td>\n",
       "      <td>Esta semana les pinchan de la gripe y Alba no ...</td>\n",
       "      <td>es</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                             final_annotation  \\\n",
       "0  1058586475737047040                      1. Likely ILI infection   \n",
       "1  1058586475737047040                      1. Likely ILI infection   \n",
       "2  1058586475737047040                      1. Likely ILI infection   \n",
       "3  1058586475737047040                      1. Likely ILI infection   \n",
       "4  1058586475737047040                      1. Likely ILI infection   \n",
       "5  1050092005806751747  3. Not Related to ILI or COVID-19 Infection   \n",
       "6  1050092005806751747  3. Not Related to ILI or COVID-19 Infection   \n",
       "7  1050092005806751747  3. Not Related to ILI or COVID-19 Infection   \n",
       "8  1050092005806751747  3. Not Related to ILI or COVID-19 Infection   \n",
       "9  1050092005806751747  3. Not Related to ILI or COVID-19 Infection   \n",
       "\n",
       "                                               tweet lang  year  overlap  \n",
       "0  @user Je ne suis pas sûr, Federer a eu une bon...   fr  2018        1  \n",
       "1  @user I'm not sure, Federer has been having a ...   en  2018        1  \n",
       "2  @user Non ne sono sicuro, Federer ha avuto una...   it  2018        1  \n",
       "3  @user Ich bin mir nicht sicher, Federer hatte ...   de  2018        1  \n",
       "4  @user No estoy seguro, Federer lleva buena sem...   es  2018        1  \n",
       "5  Cette semaine, ils se font vacciner contre la ...   fr  2018        1  \n",
       "6  This week they get a flu shot and Alba doesn't...   en  2018        1  \n",
       "7  Questa settimana viene fatto un vaccino antinf...   it  2018        1  \n",
       "8  Diese Woche bekommen sie eine Grippeimpfung un...   de  2018        1  \n",
       "9  Esta semana les pinchan de la gripe y Alba no ...   es  2018        1  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8e046899-871a-4187-bde4-db19c8a68aba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de train_idx\n",
      "  579.0\n",
      "de test_idx\n",
      "  194.0\n",
      "de valid_idx\n",
      "  194.0\n",
      "en train_idx\n",
      "  117.0\n",
      "en test_idx\n",
      "  40.0\n",
      "en valid_idx\n",
      "  39.0\n",
      "es train_idx\n",
      "  698.0\n",
      "es test_idx\n",
      "  233.0\n",
      "es valid_idx\n",
      "  233.0\n",
      "fr train_idx\n",
      "  576.0\n",
      "fr test_idx\n",
      "  193.0\n",
      "fr valid_idx\n",
      "  192.0\n",
      "it train_idx\n",
      "  597.0\n",
      "it test_idx\n",
      "  200.0\n",
      "it valid_idx\n",
      "  199.0\n"
     ]
    }
   ],
   "source": [
    "onetomany_split_idx = {}\n",
    "for lang, splits_dict in split_id.items():\n",
    "    onetomany_lang_split_idx = {}\n",
    "    for split_type, ids in splits_dict.items():                       # for each split in each language\n",
    "        print(lang, split_type)\n",
    "        sub_df = translated_df[translated_df['id'].isin(ids)]         # take only the id that exists in revised split_idx for that langauge\n",
    "        print(f'  {sub_df.shape[0]/5}')\n",
    "        # print(sub_df[['id','lang']].head())\n",
    "        onetomany_lang_split_idx[split_type] = sub_df.index.tolist()  # get the index of the selected ids and save into respective split\n",
    "    onetomany_split_idx[lang] = onetomany_lang_split_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "711cea38-d92b-4bec-a2f1-8445bccd5e96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6681\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "      <th>es</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[5830, 5831, 5832, 5833, 5834, 5835, 5836, 583...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid_idx</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            de   en   es   fr  \\\n",
       "train_idx  NaN  NaN  NaN  NaN   \n",
       "test_idx   NaN  NaN  NaN  NaN   \n",
       "valid_idx  NaN  NaN  NaN  NaN   \n",
       "\n",
       "                                                          it  \n",
       "train_idx  [5830, 5831, 5832, 5833, 5834, 5835, 5836, 583...  \n",
       "test_idx                                                 NaN  \n",
       "valid_idx                                                NaN  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = np.random.randint(0, translated_df.shape[0])\n",
    "print(n)\n",
    "test_df = pd.DataFrame.from_dict(onetomany_split_idx)\n",
    "test_df[test_df.map(lambda x: n in x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fd6c8a57-28e1-4189-a6ed-71e29e67ceb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/gaueko0/users/nmishra/multiling_fludetection/evals/eval_revisedcateg/testset0.6_0.2_0.2/onetomany_split_idx.json')"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "425f6e0a-324b-4353-b824-30fc1814a7e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ae792f7c-defe-4d0a-9bbe-15a16241514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = 'many_one_to'\n",
    "dir_path = translated_dir.joinpath(dir)\n",
    "all_files = [i for i in dir_path.glob(\"*.csv\")]\n",
    "manytoone_split_idx = {}\n",
    "for i in range(len(all_files)):\n",
    "    file = all_files[i]\n",
    "    df = pd.read_csv(file)\n",
    "    lang = file.stem[:2]\n",
    "    print(lang)\n",
    "    \n",
    "    train_ids = [i for i in split_id[j] for j in i if 'train' in i]\n",
    "    # valid_ids = \n",
    "    # test_ids\n",
    "    \n",
    "    # manytoone_lang_split_idx = {}\n",
    "    # for split, id in split_id[lang].items():\n",
    "        \n",
    "    #     manytoone_lang_split_idx[split] = df[df['id'].isin(id)].index.tolist()\n",
    "    # manytoone_split_idx[lang] = manytoone_lang_split_idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ab50adf5-4051-4a2c-8ef3-62b9d216a989",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ids = [lang,splits for lang,splits in split_id.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "3409cc20-f139-4a28-82f9-8750a5e8d12e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['d', 'e'], ['e', 'n'], ['e', 's'], ['f', 'r'], ['i', 't']]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca79b0f-03c8-4cce-9580-2ee258179ed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mari_kernel",
   "language": "python",
   "name": "mari_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

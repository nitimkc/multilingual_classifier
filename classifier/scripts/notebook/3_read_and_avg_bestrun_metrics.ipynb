{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5ea8869-1631-4a1d-af40-092aac1f971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun  4 12:03:14 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.98                 Driver Version: 535.98       CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A30                     Off | 00000000:3B:00.0 Off |                    0 |\n",
      "| N/A   46C    P0             163W / 165W |  13444MiB / 24576MiB |     82%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A30                     Off | 00000000:D8:00.0 Off |                    0 |\n",
      "| N/A   27C    P0              26W / 165W |     18MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A     14248      G   /usr/libexec/Xorg                             4MiB |\n",
      "|    0   N/A  N/A   3479303      C   python3                                   13418MiB |\n",
      "|    1   N/A  N/A     14248      G   /usr/libexec/Xorg                             4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f018a41-3c67-4047-b79b-584b145a9fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e07d86bf-a217-4aff-af4d-487c6f2033af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0707b939-4235-4572-8aca-447170d08762",
   "metadata": {},
   "source": [
    "# change eval_on to use eval_lang column info "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "006a9b32-2ad2-4f8f-a019-96815f5ecc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def desired_cols(multi_idx):\n",
    "    first_part = [i[0] for i in multi_idx]\n",
    "    second_part = [i[1].split('-') for i in multi_idx]\n",
    "    idx = []\n",
    "    counter = range(len(second_part))\n",
    "    for n,i,j in zip(counter,first_part, second_part):\n",
    "        # print('',i,j,n)\n",
    "        if (i=='metric') or ('all' in i) or ('all' in j):\n",
    "            # print('-',i,j,n)\n",
    "            pass\n",
    "        else:\n",
    "            if (i==j[1]) or (j[0]==j[1]):\n",
    "                # print('--',i,j,n)\n",
    "                idx.append(n)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6f7a4fc3-2983-4c6e-bfb3-7534300d692e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleanup (foldername, root, run=1, lc=False, n_split=3):\n",
    "    DATA_PATH = root.joinpath(foldername)\n",
    "    print(DATA_PATH)\n",
    "    df = pd.read_json(DATA_PATH.joinpath('evaluations.jsonl'), lines=True)\n",
    "    df.head()\n",
    "    \n",
    "    # clean up model name to determine trained on and tested on languages\n",
    "    df['eval_on'] = df['model_name'].str.split('eval').apply(lambda x: x[-1])\n",
    "    df['model_name'] = df['model_name'].str.split('_')\n",
    "    df['trained_on'] = df['model_name'].apply(lambda x: x[1])\n",
    "    df['model_name'] = df['model_name'].apply(lambda x: x[0])\n",
    "    \n",
    "    # isolate each item of classification report\n",
    "    df['macro_avg_precision'] = [i['macro avg']['precision'] for i in df['class_report']]\n",
    "    df['macro_avg_recall'] = [i['macro avg']['recall'] for i in df['class_report']]\n",
    "    df['support'] = [i['macro avg']['support'] for i in df['class_report']]\n",
    "    df['f1_1. Likely ILI infection'] = [i['1. Likely ILI infection']['f1-score'] for i in df['class_report']]\n",
    "    df['f1_3. Not Related to ILI or COVID-19 Infection'] = [i['3. Not Related to ILI or COVID-19 Infection']['f1-score'] for i in df['class_report']]\n",
    "    df['support_1. Likely ILI infection'] = [i['1. Likely ILI infection']['support'] for i in df['class_report']]\n",
    "    df['support_3. Not Related to ILI or COVID-19 Infection'] = [i['3. Not Related to ILI or COVID-19 Infection']['support'] for i in df['class_report']]\n",
    "    df.head()\n",
    "\n",
    "    if lc:\n",
    "        splits = [i for i in range(1,n_split+1)]\n",
    "        # print(splits)\n",
    "        start = 1\n",
    "        skip = df[['trained_on', 'eval_on']].value_counts().sum()/n_split\n",
    "        skip = skip.astype(np.int64)\n",
    "        n_exp = []\n",
    "        for i in splits:\n",
    "            # print(i)\n",
    "            end = skip*i\n",
    "            # print(start,end)\n",
    "            n_exp.extend([i for _ in range(start,end+1)])\n",
    "            start = end+1\n",
    "        if len(n_exp)==len(df):\n",
    "            df['splits'] = n_exp\n",
    "        else:\n",
    "            print(f'length of dataframe {len(df)} and split list is {len(n_exp)} not equal')\n",
    "        # df['splits'] = [1 for _ in range(1,n+1)] + [2 for _ in range(n+1,(n+1)*2)] + [3 for _ in range((n+1)*2,(n+1)*3)]\n",
    "        # df = df[df['eval_on'].str.contains('all|es-es', regex=True, case=False)]\n",
    "\n",
    "    df['run'] = run\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "7c6e7f7b-698e-4be5-a40d-347c7583cfa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_to_many_predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = Path('/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2')\n",
    "# ROOT = Path('/gaueko0/users/nmishra/multiling_fludetection/evals_mono/eval_revisedcateg/testset0.6_0.2_0.2')\n",
    "# ROOT = Path('/gaueko0/users/nmishra/multiling_fludetection/final_evals_copy')\n",
    "\n",
    "# exp = 'original' + '_predictions'\n",
    "exp = 'one_to_many' + '_predictions'\n",
    "print(exp)\n",
    "\n",
    "n_runs = list(range(1,6))\n",
    "n_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e202b2e7-7ab3-4948-a172-d33f5431f824",
   "metadata": {},
   "source": [
    "## For Regular Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "95ccdeea-25f4-4049-917e-2277c844172a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/one_to_many_predictions_run1\n",
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/one_to_many_predictions_run2\n",
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/one_to_many_predictions_run3\n",
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/one_to_many_predictions_run4\n",
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/one_to_many_predictions_run5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs = []\n",
    "for i in n_runs:\n",
    "    all_runs.append(data_cleanup(f'{exp}_run{i}', root=ROOT, run=i))\n",
    "all_results = pd.concat(all_runs)\n",
    "all_results['run'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "d2ffffb1-5518-450c-b0b2-6c1b4720c5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>trained_on</th>\n",
       "      <th colspan=\"10\" halign=\"left\">de</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"9\" halign=\"left\">it</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_on</th>\n",
       "      <th>all</th>\n",
       "      <th>de-de</th>\n",
       "      <th>de-en</th>\n",
       "      <th>de-es</th>\n",
       "      <th>de-fr</th>\n",
       "      <th>de-it</th>\n",
       "      <th>en-de</th>\n",
       "      <th>en-en</th>\n",
       "      <th>en-es</th>\n",
       "      <th>en-fr</th>\n",
       "      <th>...</th>\n",
       "      <th>fr-en</th>\n",
       "      <th>fr-es</th>\n",
       "      <th>fr-fr</th>\n",
       "      <th>fr-it</th>\n",
       "      <th>it-de</th>\n",
       "      <th>it-en</th>\n",
       "      <th>it-es</th>\n",
       "      <th>it-fr</th>\n",
       "      <th>it-it</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bernice</th>\n",
       "      <td>0.768612</td>\n",
       "      <td>0.816931</td>\n",
       "      <td>0.740265</td>\n",
       "      <td>0.741308</td>\n",
       "      <td>0.737952</td>\n",
       "      <td>0.725910</td>\n",
       "      <td>0.685628</td>\n",
       "      <td>0.743926</td>\n",
       "      <td>0.762341</td>\n",
       "      <td>0.715413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.761047</td>\n",
       "      <td>0.773646</td>\n",
       "      <td>0.756136</td>\n",
       "      <td>0.730652</td>\n",
       "      <td>0.788356</td>\n",
       "      <td>0.811124</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.783241</td>\n",
       "      <td>0.798270</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.687575</td>\n",
       "      <td>0.768862</td>\n",
       "      <td>0.721340</td>\n",
       "      <td>0.735906</td>\n",
       "      <td>0.716765</td>\n",
       "      <td>0.729621</td>\n",
       "      <td>0.622502</td>\n",
       "      <td>0.596346</td>\n",
       "      <td>0.647116</td>\n",
       "      <td>0.604918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.724814</td>\n",
       "      <td>0.718473</td>\n",
       "      <td>0.724947</td>\n",
       "      <td>0.656016</td>\n",
       "      <td>0.794066</td>\n",
       "      <td>0.777750</td>\n",
       "      <td>0.814746</td>\n",
       "      <td>0.794470</td>\n",
       "      <td>0.762611</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdeberta-v3-base</th>\n",
       "      <td>0.757516</td>\n",
       "      <td>0.818759</td>\n",
       "      <td>0.722869</td>\n",
       "      <td>0.727702</td>\n",
       "      <td>0.720471</td>\n",
       "      <td>0.720310</td>\n",
       "      <td>0.610611</td>\n",
       "      <td>0.664369</td>\n",
       "      <td>0.671729</td>\n",
       "      <td>0.648259</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752579</td>\n",
       "      <td>0.739268</td>\n",
       "      <td>0.747899</td>\n",
       "      <td>0.717921</td>\n",
       "      <td>0.757159</td>\n",
       "      <td>0.743713</td>\n",
       "      <td>0.784219</td>\n",
       "      <td>0.750627</td>\n",
       "      <td>0.749656</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter-xlm-roberta-base</th>\n",
       "      <td>0.744984</td>\n",
       "      <td>0.809623</td>\n",
       "      <td>0.724910</td>\n",
       "      <td>0.745744</td>\n",
       "      <td>0.755621</td>\n",
       "      <td>0.741114</td>\n",
       "      <td>0.648307</td>\n",
       "      <td>0.646370</td>\n",
       "      <td>0.672129</td>\n",
       "      <td>0.645665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785298</td>\n",
       "      <td>0.787578</td>\n",
       "      <td>0.771625</td>\n",
       "      <td>0.760367</td>\n",
       "      <td>0.819951</td>\n",
       "      <td>0.863462</td>\n",
       "      <td>0.868614</td>\n",
       "      <td>0.852459</td>\n",
       "      <td>0.854009</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-base</th>\n",
       "      <td>0.752017</td>\n",
       "      <td>0.814206</td>\n",
       "      <td>0.747105</td>\n",
       "      <td>0.749139</td>\n",
       "      <td>0.737556</td>\n",
       "      <td>0.739908</td>\n",
       "      <td>0.655993</td>\n",
       "      <td>0.648179</td>\n",
       "      <td>0.630213</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751241</td>\n",
       "      <td>0.740613</td>\n",
       "      <td>0.726227</td>\n",
       "      <td>0.732295</td>\n",
       "      <td>0.776693</td>\n",
       "      <td>0.812182</td>\n",
       "      <td>0.824621</td>\n",
       "      <td>0.800940</td>\n",
       "      <td>0.804504</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "trained_on                            de                                \\\n",
       "eval_on                              all     de-de     de-en     de-es   \n",
       "model_name                                                               \n",
       "bernice                         0.768612  0.816931  0.740265  0.741308   \n",
       "bert-base-multilingual-uncased  0.687575  0.768862  0.721340  0.735906   \n",
       "mdeberta-v3-base                0.757516  0.818759  0.722869  0.727702   \n",
       "twitter-xlm-roberta-base        0.744984  0.809623  0.724910  0.745744   \n",
       "xlm-roberta-base                0.752017  0.814206  0.747105  0.749139   \n",
       "\n",
       "trained_on                                                              \\\n",
       "eval_on                            de-fr     de-it     en-de     en-en   \n",
       "model_name                                                               \n",
       "bernice                         0.737952  0.725910  0.685628  0.743926   \n",
       "bert-base-multilingual-uncased  0.716765  0.729621  0.622502  0.596346   \n",
       "mdeberta-v3-base                0.720471  0.720310  0.610611  0.664369   \n",
       "twitter-xlm-roberta-base        0.755621  0.741114  0.648307  0.646370   \n",
       "xlm-roberta-base                0.737556  0.739908  0.655993  0.648179   \n",
       "\n",
       "trained_on                                          ...        it            \\\n",
       "eval_on                            en-es     en-fr  ...     fr-en     fr-es   \n",
       "model_name                                          ...                       \n",
       "bernice                         0.762341  0.715413  ...  0.761047  0.773646   \n",
       "bert-base-multilingual-uncased  0.647116  0.604918  ...  0.724814  0.718473   \n",
       "mdeberta-v3-base                0.671729  0.648259  ...  0.752579  0.739268   \n",
       "twitter-xlm-roberta-base        0.672129  0.645665  ...  0.785298  0.787578   \n",
       "xlm-roberta-base                0.630213  0.645349  ...  0.751241  0.740613   \n",
       "\n",
       "trained_on                                                              \\\n",
       "eval_on                            fr-fr     fr-it     it-de     it-en   \n",
       "model_name                                                               \n",
       "bernice                         0.756136  0.730652  0.788356  0.811124   \n",
       "bert-base-multilingual-uncased  0.724947  0.656016  0.794066  0.777750   \n",
       "mdeberta-v3-base                0.747899  0.717921  0.757159  0.743713   \n",
       "twitter-xlm-roberta-base        0.771625  0.760367  0.819951  0.863462   \n",
       "xlm-roberta-base                0.726227  0.732295  0.776693  0.812182   \n",
       "\n",
       "trained_on                                                      metric  \n",
       "eval_on                            it-es     it-fr     it-it            \n",
       "model_name                                                              \n",
       "bernice                         0.813187  0.783241  0.798270  f1_macro  \n",
       "bert-base-multilingual-uncased  0.814746  0.794470  0.762611  f1_macro  \n",
       "mdeberta-v3-base                0.784219  0.750627  0.749656  f1_macro  \n",
       "twitter-xlm-roberta-base        0.868614  0.852459  0.854009  f1_macro  \n",
       "xlm-roberta-base                0.824621  0.800940  0.804504  f1_macro  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = pd.pivot_table(all_results, values='f1_macro', columns=['trained_on','eval_on'], index='model_name',  aggfunc = 'mean')\n",
    "recall = pd.pivot_table(all_results, values='macro_avg_recall', columns=['trained_on','eval_on'], index='model_name',  aggfunc = 'mean')\n",
    "precision = pd.pivot_table(all_results, values='macro_avg_precision', columns=['trained_on','eval_on'], index='model_name',  aggfunc = 'mean')\n",
    "accuracy = pd.pivot_table(all_results, values='accuracy', columns=['trained_on','eval_on'], index='model_name',  aggfunc = 'mean')\n",
    "support = pd.pivot_table(all_results, values='support', columns=['trained_on','eval_on'], index='model_name',  aggfunc = 'mean')\n",
    "f1_macro['metric'] = 'f1_macro'\n",
    "recall['metric'] = 'recall'\n",
    "precision['metric'] = 'precision'\n",
    "accuracy['metric'] = 'accuracy'\n",
    "support['metric'] = 'support'\n",
    "all_eval = pd.concat([f1_macro, recall, precision, accuracy,support])\n",
    "all_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "21dd113b-f5f4-4225-ab45-99b6e1a34bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eval.to_csv(ROOT.joinpath(f'{exp}_avg_of_5runs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f8597054-68e3-4985-8a7c-b03e324d80ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>trained_on</th>\n",
       "      <th colspan=\"9\" halign=\"left\">de</th>\n",
       "      <th>en</th>\n",
       "      <th>...</th>\n",
       "      <th>fr</th>\n",
       "      <th colspan=\"9\" halign=\"left\">it</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eval_on</th>\n",
       "      <th>de-de</th>\n",
       "      <th>en-de</th>\n",
       "      <th>en-en</th>\n",
       "      <th>es-de</th>\n",
       "      <th>es-es</th>\n",
       "      <th>fr-de</th>\n",
       "      <th>fr-fr</th>\n",
       "      <th>it-de</th>\n",
       "      <th>it-it</th>\n",
       "      <th>de-de</th>\n",
       "      <th>...</th>\n",
       "      <th>it-it</th>\n",
       "      <th>de-de</th>\n",
       "      <th>de-it</th>\n",
       "      <th>en-en</th>\n",
       "      <th>en-it</th>\n",
       "      <th>es-es</th>\n",
       "      <th>es-it</th>\n",
       "      <th>fr-fr</th>\n",
       "      <th>fr-it</th>\n",
       "      <th>it-it</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.806186</td>\n",
       "      <td>0.658000</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.720858</td>\n",
       "      <td>0.755536</td>\n",
       "      <td>0.708187</td>\n",
       "      <td>0.716269</td>\n",
       "      <td>0.866000</td>\n",
       "      <td>0.870400</td>\n",
       "      <td>0.762680</td>\n",
       "      <td>...</td>\n",
       "      <td>0.885600</td>\n",
       "      <td>0.790309</td>\n",
       "      <td>0.710722</td>\n",
       "      <td>0.705000</td>\n",
       "      <td>0.699000</td>\n",
       "      <td>0.844635</td>\n",
       "      <td>0.809099</td>\n",
       "      <td>0.752332</td>\n",
       "      <td>0.740311</td>\n",
       "      <td>0.907800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.805676</td>\n",
       "      <td>0.644608</td>\n",
       "      <td>0.659838</td>\n",
       "      <td>0.709749</td>\n",
       "      <td>0.750301</td>\n",
       "      <td>0.680158</td>\n",
       "      <td>0.689074</td>\n",
       "      <td>0.713535</td>\n",
       "      <td>0.726371</td>\n",
       "      <td>0.761673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780008</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>0.702767</td>\n",
       "      <td>0.701974</td>\n",
       "      <td>0.678678</td>\n",
       "      <td>0.843545</td>\n",
       "      <td>0.804476</td>\n",
       "      <td>0.745367</td>\n",
       "      <td>0.719450</td>\n",
       "      <td>0.793810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.660871</td>\n",
       "      <td>0.669024</td>\n",
       "      <td>0.740264</td>\n",
       "      <td>0.764686</td>\n",
       "      <td>0.728303</td>\n",
       "      <td>0.735754</td>\n",
       "      <td>0.751337</td>\n",
       "      <td>0.753352</td>\n",
       "      <td>0.767044</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778590</td>\n",
       "      <td>0.799054</td>\n",
       "      <td>0.727931</td>\n",
       "      <td>0.707334</td>\n",
       "      <td>0.714598</td>\n",
       "      <td>0.848774</td>\n",
       "      <td>0.826822</td>\n",
       "      <td>0.752220</td>\n",
       "      <td>0.760207</td>\n",
       "      <td>0.848292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.806231</td>\n",
       "      <td>0.649495</td>\n",
       "      <td>0.666061</td>\n",
       "      <td>0.716569</td>\n",
       "      <td>0.753313</td>\n",
       "      <td>0.684590</td>\n",
       "      <td>0.694318</td>\n",
       "      <td>0.697725</td>\n",
       "      <td>0.720078</td>\n",
       "      <td>0.763001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.784471</td>\n",
       "      <td>0.788812</td>\n",
       "      <td>0.707940</td>\n",
       "      <td>0.704949</td>\n",
       "      <td>0.682929</td>\n",
       "      <td>0.843591</td>\n",
       "      <td>0.805674</td>\n",
       "      <td>0.744329</td>\n",
       "      <td>0.719207</td>\n",
       "      <td>0.764039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>194.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>194.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>193.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "trained_on          de                                                \\\n",
       "eval_on          de-de      en-de      en-en       es-de       es-es   \n",
       "metric                                                                 \n",
       "accuracy      0.806186   0.658000   0.664000    0.720858    0.755536   \n",
       "f1_macro      0.805676   0.644608   0.659838    0.709749    0.750301   \n",
       "precision     0.809249   0.660871   0.669024    0.740264    0.764686   \n",
       "recall        0.806231   0.649495   0.666061    0.716569    0.753313   \n",
       "support     194.000000  40.000000  40.000000  233.000000  233.000000   \n",
       "\n",
       "trained_on                                                          en  ...  \\\n",
       "eval_on          fr-de       fr-fr       it-de       it-it       de-de  ...   \n",
       "metric                                                                  ...   \n",
       "accuracy      0.708187    0.716269    0.866000    0.870400    0.762680  ...   \n",
       "f1_macro      0.680158    0.689074    0.713535    0.726371    0.761673  ...   \n",
       "precision     0.728303    0.735754    0.751337    0.753352    0.767044  ...   \n",
       "recall        0.684590    0.694318    0.697725    0.720078    0.763001  ...   \n",
       "support     193.000000  193.000000  200.000000  200.000000  194.000000  ...   \n",
       "\n",
       "trained_on          fr          it                                    \\\n",
       "eval_on          it-it       de-de       de-it      en-en      en-it   \n",
       "metric                                                                 \n",
       "accuracy      0.885600    0.790309    0.710722   0.705000   0.699000   \n",
       "f1_macro      0.780008    0.787945    0.702767   0.701974   0.678678   \n",
       "precision     0.778590    0.799054    0.727931   0.707334   0.714598   \n",
       "recall        0.784471    0.788812    0.707940   0.704949   0.682929   \n",
       "support     200.000000  194.000000  194.000000  40.000000  40.000000   \n",
       "\n",
       "trained_on                                                              \n",
       "eval_on          es-es       es-it       fr-fr       fr-it       it-it  \n",
       "metric                                                                  \n",
       "accuracy      0.844635    0.809099    0.752332    0.740311    0.907800  \n",
       "f1_macro      0.843545    0.804476    0.745367    0.719450    0.793810  \n",
       "precision     0.848774    0.826822    0.752220    0.760207    0.848292  \n",
       "recall        0.843591    0.805674    0.744329    0.719207    0.764039  \n",
       "support     233.000000  233.000000  193.000000  193.000000  200.000000  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_metrics = all_eval.groupby('metric').mean()\n",
    "selected_idx = desired_cols(avg_metrics.columns)\n",
    "avg_metrics = avg_metrics[avg_metrics.columns[selected_idx]]\n",
    "avg_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1a915282-a575-47c7-b8a9-5b9d73794822",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_metrics.to_csv(ROOT.joinpath(f'avg_{exp}.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c62287-8b5f-4313-b46c-deb37fe92afb",
   "metadata": {},
   "source": [
    "## For Learning Curve Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1f9c817-11af-4ae0-9252-d14246c9c05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "es_learningcurve_predictions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT = Path('/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2')\n",
    "# ROOT = Path('/gaueko0/users/nmishra/multiling_fludetection/evals_mono/eval_revisedcateg/testset0.6_0.2_0.2')\n",
    "# ROOT = Path('/gaueko0/users/nmishra/multiling_fludetection/final_evals_copy')\n",
    "\n",
    "exp = 'es_learningcurve' + '_predictions'\n",
    "print(exp)\n",
    "\n",
    "n_runs = list(range(1,6))\n",
    "n_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca6bbae1-561f-4d13-b3b3-21f0d9cf9f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/es_learningcurve_predictions_run1\n",
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/es_learningcurve_predictions_run2\n",
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/es_learningcurve_predictions_run3\n",
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/es_learningcurve_predictions_run4\n",
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/es_learningcurve_predictions_run5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for learning curve runs\n",
    "lc=True\n",
    "all_runs = []\n",
    "for i in n_runs:\n",
    "    all_runs.append(data_cleanup(f'{exp}_run{i}', root=ROOT, run=i, lc=lc, n_split=3))\n",
    "all_results = pd.concat(all_runs)\n",
    "all_results['run'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a348c86b-0250-40ee-bf60-39ad599f58df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>trained_on</th>\n",
       "      <th colspan=\"20\" halign=\"left\">es</th>\n",
       "      <th>metric</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>eval_on</th>\n",
       "      <th>all</th>\n",
       "      <th>de-de</th>\n",
       "      <th>de-en</th>\n",
       "      <th>de-es</th>\n",
       "      <th>de-fr</th>\n",
       "      <th>de-it</th>\n",
       "      <th>en-de</th>\n",
       "      <th>en-en</th>\n",
       "      <th>en-es</th>\n",
       "      <th>en-fr</th>\n",
       "      <th>...</th>\n",
       "      <th>fr-en</th>\n",
       "      <th>fr-es</th>\n",
       "      <th>fr-fr</th>\n",
       "      <th>fr-it</th>\n",
       "      <th>it-de</th>\n",
       "      <th>it-en</th>\n",
       "      <th>it-es</th>\n",
       "      <th>it-fr</th>\n",
       "      <th>it-it</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>splits</th>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>bernice</th>\n",
       "      <td>0.518841</td>\n",
       "      <td>0.443645</td>\n",
       "      <td>0.444375</td>\n",
       "      <td>0.600558</td>\n",
       "      <td>0.608932</td>\n",
       "      <td>0.538297</td>\n",
       "      <td>0.382882</td>\n",
       "      <td>0.356614</td>\n",
       "      <td>0.494362</td>\n",
       "      <td>0.560320</td>\n",
       "      <td>...</td>\n",
       "      <td>0.397100</td>\n",
       "      <td>0.525261</td>\n",
       "      <td>0.552734</td>\n",
       "      <td>0.543226</td>\n",
       "      <td>0.329608</td>\n",
       "      <td>0.310361</td>\n",
       "      <td>0.478532</td>\n",
       "      <td>0.483648</td>\n",
       "      <td>0.404193</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.426793</td>\n",
       "      <td>0.487376</td>\n",
       "      <td>0.430427</td>\n",
       "      <td>0.429027</td>\n",
       "      <td>0.464888</td>\n",
       "      <td>0.439815</td>\n",
       "      <td>0.405742</td>\n",
       "      <td>0.377625</td>\n",
       "      <td>0.408529</td>\n",
       "      <td>0.409570</td>\n",
       "      <td>...</td>\n",
       "      <td>0.424264</td>\n",
       "      <td>0.430967</td>\n",
       "      <td>0.460316</td>\n",
       "      <td>0.451445</td>\n",
       "      <td>0.291303</td>\n",
       "      <td>0.266478</td>\n",
       "      <td>0.275751</td>\n",
       "      <td>0.302653</td>\n",
       "      <td>0.297472</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mdeberta-v3-base</th>\n",
       "      <td>0.283930</td>\n",
       "      <td>0.328720</td>\n",
       "      <td>0.328720</td>\n",
       "      <td>0.328720</td>\n",
       "      <td>0.328720</td>\n",
       "      <td>0.328720</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>0.310345</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.305755</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twitter-xlm-roberta-base</th>\n",
       "      <td>0.804349</td>\n",
       "      <td>0.778923</td>\n",
       "      <td>0.733858</td>\n",
       "      <td>0.727907</td>\n",
       "      <td>0.726933</td>\n",
       "      <td>0.732556</td>\n",
       "      <td>0.767898</td>\n",
       "      <td>0.750814</td>\n",
       "      <td>0.759467</td>\n",
       "      <td>0.709873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.791114</td>\n",
       "      <td>0.806441</td>\n",
       "      <td>0.767220</td>\n",
       "      <td>0.777997</td>\n",
       "      <td>0.746962</td>\n",
       "      <td>0.778725</td>\n",
       "      <td>0.782729</td>\n",
       "      <td>0.746078</td>\n",
       "      <td>0.765960</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-base</th>\n",
       "      <td>0.305866</td>\n",
       "      <td>0.343629</td>\n",
       "      <td>0.333175</td>\n",
       "      <td>0.346724</td>\n",
       "      <td>0.342464</td>\n",
       "      <td>0.334948</td>\n",
       "      <td>0.316408</td>\n",
       "      <td>0.323867</td>\n",
       "      <td>0.345974</td>\n",
       "      <td>0.327397</td>\n",
       "      <td>...</td>\n",
       "      <td>0.330938</td>\n",
       "      <td>0.330190</td>\n",
       "      <td>0.342427</td>\n",
       "      <td>0.326449</td>\n",
       "      <td>0.162291</td>\n",
       "      <td>0.152211</td>\n",
       "      <td>0.166127</td>\n",
       "      <td>0.170944</td>\n",
       "      <td>0.164222</td>\n",
       "      <td>f1_macro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "trained_on                                   es                                \\\n",
       "eval_on                                     all     de-de     de-en     de-es   \n",
       "splits model_name                                                               \n",
       "1      bernice                         0.518841  0.443645  0.444375  0.600558   \n",
       "       bert-base-multilingual-uncased  0.426793  0.487376  0.430427  0.429027   \n",
       "       mdeberta-v3-base                0.283930  0.328720  0.328720  0.328720   \n",
       "       twitter-xlm-roberta-base        0.804349  0.778923  0.733858  0.727907   \n",
       "       xlm-roberta-base                0.305866  0.343629  0.333175  0.346724   \n",
       "\n",
       "trained_on                                                                     \\\n",
       "eval_on                                   de-fr     de-it     en-de     en-en   \n",
       "splits model_name                                                               \n",
       "1      bernice                         0.608932  0.538297  0.382882  0.356614   \n",
       "       bert-base-multilingual-uncased  0.464888  0.439815  0.405742  0.377625   \n",
       "       mdeberta-v3-base                0.328720  0.328720  0.310345  0.310345   \n",
       "       twitter-xlm-roberta-base        0.726933  0.732556  0.767898  0.750814   \n",
       "       xlm-roberta-base                0.342464  0.334948  0.316408  0.323867   \n",
       "\n",
       "trained_on                                                 ...            \\\n",
       "eval_on                                   en-es     en-fr  ...     fr-en   \n",
       "splits model_name                                          ...             \n",
       "1      bernice                         0.494362  0.560320  ...  0.397100   \n",
       "       bert-base-multilingual-uncased  0.408529  0.409570  ...  0.424264   \n",
       "       mdeberta-v3-base                0.310345  0.310345  ...  0.305755   \n",
       "       twitter-xlm-roberta-base        0.759467  0.709873  ...  0.791114   \n",
       "       xlm-roberta-base                0.345974  0.327397  ...  0.330938   \n",
       "\n",
       "trained_on                                                                     \\\n",
       "eval_on                                   fr-es     fr-fr     fr-it     it-de   \n",
       "splits model_name                                                               \n",
       "1      bernice                         0.525261  0.552734  0.543226  0.329608   \n",
       "       bert-base-multilingual-uncased  0.430967  0.460316  0.451445  0.291303   \n",
       "       mdeberta-v3-base                0.305755  0.305755  0.305755  0.130435   \n",
       "       twitter-xlm-roberta-base        0.806441  0.767220  0.777997  0.746962   \n",
       "       xlm-roberta-base                0.330190  0.342427  0.326449  0.162291   \n",
       "\n",
       "trained_on                                                                     \\\n",
       "eval_on                                   it-en     it-es     it-fr     it-it   \n",
       "splits model_name                                                               \n",
       "1      bernice                         0.310361  0.478532  0.483648  0.404193   \n",
       "       bert-base-multilingual-uncased  0.266478  0.275751  0.302653  0.297472   \n",
       "       mdeberta-v3-base                0.130435  0.130435  0.130435  0.130435   \n",
       "       twitter-xlm-roberta-base        0.778725  0.782729  0.746078  0.765960   \n",
       "       xlm-roberta-base                0.152211  0.166127  0.170944  0.164222   \n",
       "\n",
       "trained_on                               metric  \n",
       "eval_on                                          \n",
       "splits model_name                                \n",
       "1      bernice                         f1_macro  \n",
       "       bert-base-multilingual-uncased  f1_macro  \n",
       "       mdeberta-v3-base                f1_macro  \n",
       "       twitter-xlm-roberta-base        f1_macro  \n",
       "       xlm-roberta-base                f1_macro  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_macro = pd.pivot_table(all_results, values='f1_macro', columns=['trained_on','eval_on'], index=['splits','model_name'], aggfunc = 'mean')\n",
    "recall = pd.pivot_table(all_results, values='macro_avg_recall', columns=['trained_on','eval_on'], index=['splits','model_name'], aggfunc = 'mean')\n",
    "precision = pd.pivot_table(all_results, values='macro_avg_precision', columns=['trained_on','eval_on'], index=['splits','model_name'], aggfunc = 'mean')\n",
    "accuracy = pd.pivot_table(all_results, values='accuracy', columns=['trained_on','eval_on'], index=['splits','model_name'], aggfunc = 'mean')\n",
    "support = pd.pivot_table(all_results, values='support', columns=['trained_on','eval_on'], index=['splits','model_name'], aggfunc = 'mean')\n",
    "f1_macro['metric'] = 'f1_macro'\n",
    "recall['metric'] = 'recall'\n",
    "precision['metric'] = 'precision'\n",
    "accuracy['metric'] = 'accuracy'\n",
    "support['metric'] = 'support'\n",
    "all_eval = pd.concat([f1_macro, recall, precision, accuracy,support])\n",
    "all_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1fa12a7-a07a-4176-b031-478ba887986f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/multiling_fludetection/final_evals/eval_revisedcateg/testset0.6_0.2_0.2/es_learningcurve_predictions_avg_of_5runs.csv\n"
     ]
    }
   ],
   "source": [
    "print(ROOT.joinpath(f'{exp}_avg_of_5runs.csv'))\n",
    "# all_eval.to_csv(ROOT.joinpath(f'{exp}_avg_of_5runs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c53a2fb3-ac89-45f8-bf93-bdb036876c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_eval.to_csv(ROOT.joinpath(f'all{exp}_avg_of_5runs.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33edff61-2e09-4c36-b913-960766fe021e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel ILI Test",
   "language": "python",
   "name": "ipykernel-ili-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

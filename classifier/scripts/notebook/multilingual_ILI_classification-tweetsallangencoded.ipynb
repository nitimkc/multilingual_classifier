{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e58c69-7643-41ba-aa8c-9e8f5f656ca5",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Run Setting](#runsettings)\n",
    "2. [Reader](#reader)\n",
    "    1. [Sub paragraph](#subparagraph1)\n",
    "3. [Processor](#processor)\n",
    "4. [Trainer](#trainer)\n",
    "5. [Evaluater](#evaluater)\n",
    "6. [Wrapper](#wrapper)\n",
    "7. [Load Data](#loaddata)\n",
    "8. [Do Training](#dotrianing)\n",
    "\n",
    "## Configurations to run the script\n",
    "<a name=\"runsettings\"></a>\n",
    "Details can be added here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6c60089-6388-45d8-92b3-db352e204982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B disabled.\n"
     ]
    }
   ],
   "source": [
    "!wandb disabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b38a1f-9115-4899-bb08-88248fe2d9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "print(os.environ[\"CUDA_VISIBLE_DEVICES\"])\n",
    "\n",
    "# os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a2a8543-123e-4ac3-921d-5855f10f549b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA_LAUNCH_BLOCKING=1: Command not found.\n"
     ]
    }
   ],
   "source": [
    "!CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e92e7041-b0c2-4aaf-b5a6-a4e933628a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  9 12:32:22 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:01:00.0 Off |                    0 |\n",
      "| N/A   24C    P0              59W / 500W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A100-SXM4-80GB          On  | 00000000:41:00.0 Off |                    0 |\n",
      "| N/A   22C    P0              59W / 500W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A100-SXM4-80GB          On  | 00000000:81:00.0 Off |                    0 |\n",
      "| N/A   21C    P0              60W / 500W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A100-SXM4-80GB          On  | 00000000:C1:00.0 Off |                    0 |\n",
      "| N/A   21C    P0              61W / 500W |      4MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8a4b66-bf79-4a6b-9cff-cd2140d9e2a9",
   "metadata": {},
   "source": [
    "## Reader \n",
    "<a name=\"reader\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5584c8d-752a-420f-846b-00dd66b0d7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "1. Read annotated multilingual ILI data using CustomDataset.\n",
    "2. Convert encoded features and labels to dataset objects for integration with transformers model training.\n",
    "\n",
    "\"\"\" \n",
    "\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "\n",
    "    \n",
    "class CustomDataset(object):\n",
    "    def __init__(self, file_name, savepath=None):\n",
    "        \n",
    "        self._file_name = file_name\n",
    "        if savepath is not None:\n",
    "            self._savepath = Path(savepath)\n",
    "            self._savepath.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self.data =  pd.read_csv(self._file_name)\n",
    "        self.tweets = self.data['tweet']\n",
    "        self.labels = self.data['final_annotation']\n",
    "\n",
    "    def __len__(self):    \n",
    "        if len(self.tweets) != len(self.labels):\n",
    "            raise sys.exit(f\"Number of tweets({len(self.tweets)}) and its labels({len(self.labels)}) do not match.\")\n",
    "        else:\n",
    "            return len(self.labels)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        tweet = self.tweets.iloc[idx] \n",
    "        label = self.labels.iloc[idx] \n",
    "        return tweet, label\n",
    "    \n",
    "    def getsplitidx(self, test_split=0.2, valid_split=None, group='lang', stratify_label='final_annotation'):\n",
    "        \n",
    "        # group day by language and then perform stratified split by categories and save indices as json\n",
    "        lang_split_idx = {}\n",
    "        for grp, grp_df in self.data.groupby(group): \n",
    "            train, test = train_test_split(grp_df, test_size=test_split, stratify=grp_df[stratify_label])\n",
    "            if valid_split is not None:\n",
    "                train, valid = train_test_split(train, test_size=valid_split, stratify=train[stratify_label])\n",
    "        \n",
    "            print(f\"\\nDistribution of classes in train set in {grp}\\n{train[stratify_label].value_counts()}\")\n",
    "            print(f\"Distribution of classes in test set in {grp}\\n\\{test[stratify_label].value_counts()}\")\n",
    "            lang_split_idx[grp] = {'train_idx':train.index.values.tolist(), \n",
    "                                   'test_idx':test.index.values.tolist()\n",
    "                                  }\n",
    "            if valid_split is not None:\n",
    "                print(f\"Distribution of classes in valid set in {grp}\\n{valid[stratify_label].value_counts()}\\n\")\n",
    "                lang_split_idx[grp] = {'train_idx':train.index.values.tolist(), \n",
    "                                       'test_idx':test.index.values.tolist(), \n",
    "                                       'valid_idx':valid.index.values.tolist()\n",
    "                                      }\n",
    "                \n",
    "        if self._savepath is not None:\n",
    "            with open(self._savepath.joinpath(\"lang_split_idx.json\"), \"w\")  as f:\n",
    "                json.dump(lang_split_idx, f)\n",
    "        return lang_split_idx\n",
    "\n",
    "# https://huggingface.co/transformers/v3.5.1/custom_datasets.html    \n",
    "class EncodedDataset(torch.utils.data.Dataset): # torch\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # item = {key: torch.tensor(val[idx]).clone().detach() for key, val in self.encodings.items()}\n",
    "        # item['labels'] = torch.tensor(self.labels[idx]).clone().detach()\n",
    "        \n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getdatasetsplits__(self, indices):\n",
    "        split = self.__getitem__(indices)\n",
    "        dataset = Dataset.from_dict(split)\n",
    "        return dataset\n",
    "    \n",
    "    def splitdata(self, split_indices):\n",
    "        allsplits = []\n",
    "        for i in split_indices:\n",
    "            allsplits.append(self.__getdatasetsplits__(i))\n",
    "        return allsplits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774b5eaa-a664-469c-a5a7-16c62386506a",
   "metadata": {},
   "source": [
    "## Preprocessor \n",
    "<a name=\"processor\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6aae53cc-845c-48ab-ad04-cbce028651c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2-*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "1. Process data based on model checkpoint and configurations provided in final_configs.json \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import Subset, DataLoader\n",
    "\n",
    "class DataProcessor(object):\n",
    "    \n",
    "    def __init__(self, config, encoder=LabelEncoder(), return_type_ids=False):\n",
    "        \n",
    "        self._config = config\n",
    "        self._encoder = encoder\n",
    "        self._return_type_ids = return_type_ids\n",
    "        \n",
    "        self.model_checkpoint = self._config['MODEL_CHECKPOINT']\n",
    "        if ((self._config['MAX_LEN'] is not None and self._config['MAX_LEN']>128) and ('bernice' in self.model_checkpoint)):\n",
    "            self._config['MAX_LEN'] = 128\n",
    "            print(f\"Max length for {self.model_checkpoint} set to 128 by default\")\n",
    "        print(f\"\\nFinal configurations for processing training + validation data\\n{self._config}\")\n",
    "\n",
    "    def label_encoder(self, target):\n",
    "        le = self._encoder\n",
    "        return le.fit_transform(target)\n",
    "\n",
    "    def tokenizer(self):    \n",
    "        # statistical tokenizer # subwords, chunks of words \n",
    "        return AutoTokenizer.from_pretrained(self.model_checkpoint, \n",
    "                                             use_fast = False,    # use one of the fast tokenizers (backed by Rust), available for almost all models\n",
    "                                             # max_length=self._config['MAX_LEN'] # pass max length only when encoding not when instantiating the tokenizer\n",
    "                                             )\n",
    "    \n",
    "    def feature_encoder(self, features):\n",
    "        tokenizer = self.tokenizer()\n",
    "\n",
    "        feature_encodings = tokenizer.batch_encode_plus(\n",
    "            features.astype(str).values.tolist(), \n",
    "            padding=True, \n",
    "            truncation=True, \n",
    "            max_length=self._config['MAX_LEN'],\n",
    "            # is_split_into_words=True, # added for multilingual versions refer 4624.err\n",
    "            # return_attention_mask=True,\n",
    "            return_token_type_ids=self._return_type_ids, \n",
    "            return_tensors='pt',\n",
    "            )\n",
    "        print(f\"Dimensions of encoded features: {feature_encodings['input_ids'].shape}\")\n",
    "        print(f\"Encoding contains: {[i for i in feature_encodings.keys()]}\")\n",
    "        return feature_encodings\n",
    "\n",
    "    def encoded_data(self, features, labels):\n",
    "        encoded_features = self.feature_encoder(features)\n",
    "        encoded_labels = self.label_encoder(labels)\n",
    "        if encoded_features['input_ids'].shape[0] == encoded_labels.shape[0]:\n",
    "            return encoded_features, encoded_labels\n",
    "        else:\n",
    "            print(\"encoded features and labels do not have same length\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6eee10-5b1b-4542-9905-607447e784ee",
   "metadata": {},
   "source": [
    "## Trainer \n",
    "<a name=\"trainer\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d53d368f-08d2-4143-aa67-b9cbd4ee603b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3-*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "1. Train model once the best hyperparameters from final_configs.json that were identified using classification_wandb.py\n",
    "2. Get predictions from the trained model with boolen flag\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import shutil\n",
    "from types import SimpleNamespace\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "from transformers import EarlyStoppingCallback, TrainerCallback\n",
    "\n",
    "import evaluate\n",
    "# from evaluater import evaluation_display\n",
    "\n",
    "hyperparams = ['MODEL_CHECKPOINT','BATCH_SIZE','LEARNING_RATE','EPOCHS','MAX_LEN']\n",
    "\n",
    "# class PrintClassificationCallback(TrainerCallback):\n",
    "#     def on_evaluate(self, args, state, control, logs=None, **kwargs):\n",
    "#         print(\"Called after evaluation phase\")\n",
    "\n",
    "class ModelTrainer(object):\n",
    "\n",
    "    def __init__(self, run_config, train_dataset, valid_dataset, test_dataset, \n",
    "                 tokenizer, savepath, cachepath, lang_to_train='all'):     \n",
    "\n",
    "        self._run_config = run_config\n",
    "        if not all(k in self._run_config.keys() for k in hyperparams):\n",
    "            sys.exit(f\"provide all required hyperparams: {hyperparams}\")\n",
    "            \n",
    "        self.model_checkpoint = self._run_config['MODEL_CHECKPOINT']\n",
    "        self.model_name = self.model_checkpoint.split('/')[-1]\n",
    "    \n",
    "        self._train_dataset = train_dataset\n",
    "        self._valid_dataset = valid_dataset\n",
    "        self._test_dataset = test_dataset\n",
    "        self._train_dataset.cleanup_cache_files()\n",
    "\n",
    "        self._tokenizer = tokenizer\n",
    "\n",
    "        self._savepath = savepath\n",
    "        self.modelpath = self._savepath.joinpath('models')\n",
    "        self.modelpath.mkdir(parents=True, exist_ok=True)\n",
    "        self._cachepath = cachepath\n",
    "\n",
    "        self._lang_to_train = lang_to_train\n",
    "        # self._target_names = self._run_config['TARGET_NAMES']\n",
    "        self.num_labels = len(self._run_config['TARGET_NAMES'])\n",
    "        print(f\"{self.num_labels} classes in {self._lang_to_train} language\")\n",
    "\n",
    "    def get_model(self):\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(self.model_checkpoint,\n",
    "                                                                   num_labels = self.num_labels,\n",
    "                                                                   cache_dir = self._cachepath,\n",
    "                                                                #    output_attentions=False,\n",
    "                                                                #    output_hidden_states=False,\n",
    "                                                                #    ignore_mismatched_sizes=True,\n",
    "                                                                )\n",
    "        # print(model)\n",
    "        return model\n",
    "        \n",
    "    def compute_metrics(self, eval_pred, eval_metric=\"f1\"):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        # evaluation_display(labels, predictions, self.num_labels, self._target_names) # print only for now\n",
    "        metric = evaluate.load(eval_metric)\n",
    "        return metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "\n",
    "    def train_eval(self, get_pred=False, metric_name=\"f1\", hyperparam_search=False):\n",
    "        \n",
    "        out_dir = self.modelpath.joinpath(f\"{self.model_name}-{self._lang_to_train}-finetuned\")\n",
    "        print(f\"Model to be saved in {out_dir}\")\n",
    "        log_dir = self.modelpath.parent.joinpath('logs').joinpath(f\"{self.model_name}-{self._lang_to_train}-finetuned\")\n",
    "        log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        config = SimpleNamespace(**{i.lower():j for i,j in self._run_config.items() if i in hyperparams})\n",
    "        print(f\"\\nTraining model using with configurations:\\n{config}\")\n",
    "        \n",
    "        # attributes to customize the training\n",
    "        args = TrainingArguments(\n",
    "            save_total_limit=2,\n",
    "            output_dir=str(out_dir),\n",
    "            overwrite_output_dir = True,\n",
    "            logging_dir = str(log_dir),\n",
    "            \n",
    "            learning_rate = config.learning_rate,\n",
    "            per_device_train_batch_size = config.batch_size,\n",
    "            per_device_eval_batch_size = config.batch_size,\n",
    "            num_train_epochs = config.epochs,\n",
    "            # weight_decay = config.weight_decay,\n",
    "            \n",
    "            evaluation_strategy = \"epoch\",\n",
    "            save_strategy = \"epoch\",   \n",
    "            logging_strategy = 'epoch',\n",
    "            \n",
    "            # logging_steps= 1,\n",
    "            eval_accumulation_steps = 1,\n",
    "            \n",
    "            metric_for_best_model = metric_name,\n",
    "            load_best_model_at_end = True,\n",
    "            \n",
    "            push_to_hub = False, # push the model to the Hub regularly during training\n",
    "            # report_to='wandb',  # turn on wandb logging\n",
    "            )\n",
    "\n",
    "        # https://huggingface.co/docs/transformers/main_classes/trainer#trainer\n",
    "        # https://github.com/huggingface/transformers/blob/v4.35.2/src/transformers/trainer.py#L231\n",
    "        trainer = Trainer(\n",
    "            model_init = self.get_model,\n",
    "            args = args,\n",
    "            train_dataset = self._train_dataset,\n",
    "            eval_dataset = self._valid_dataset,\n",
    "            tokenizer = self._tokenizer,\n",
    "            compute_metrics = self.compute_metrics,\n",
    "            callbacks = [EarlyStoppingCallback(3, 0.0)]\n",
    "            )\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        # print(torch.cuda.memory_summary(device=None, abbreviated=True))\n",
    "        \n",
    "        # try later setup hyperparam here instead of wandb\n",
    "        # # https://huggingface.co/docs/transformers/hpo_train\n",
    "        # if hyperparam_search:\n",
    "        #     best_run = trainer.hyperparameter_search(n_trials=10, direction=\"maximize\")\n",
    "        #     print(f\"best run for {self._model_checkpoint} is {best_run.hyperparameters.items()}\")\n",
    "        #     for n, v in best_run.hyperparameters.items():\n",
    "        #         setattr(trainer.args, n, v)\n",
    "\n",
    "        trainer.train()\n",
    "        trainer.evaluate()\n",
    "        print(f\"free space by deleting: {out_dir}\")\n",
    "        shutil.rmtree(out_dir, ignore_errors=True)\n",
    "        \n",
    "        if get_pred:\n",
    "            print(f\"\\nGetting Predictions on Test dataset\")\n",
    "            logits, labels, metrics = trainer.predict(self._test_dataset)\n",
    "            predictions = np.argmax(logits, axis=-1)\n",
    "            return trainer, (labels, predictions)    \n",
    "        else:\n",
    "            return trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a7ef1-8ccc-4913-9b09-da592e170fbe",
   "metadata": {},
   "source": [
    "## Evaluater \n",
    "<a name=\"evaluater\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceda8f52-3fc2-4a51-8544-414a82f1d499",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4-*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "1. Evaluate the model performance per language.\n",
    "2. Evaluate performance per category during each epoch.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.metrics import multilabel_confusion_matrix, classification_report\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluation_display(y, y_pred, labels_map=None, plot=False):\n",
    "    \n",
    "    if labels_map is not None:\n",
    "        labels_idx = [k for k,v in labels_map.items() if k in y.unique()]\n",
    "        labels_name = [v for k,v in labels_map.items() if k in y.unique()]\n",
    "    else:\n",
    "        labels_idx = None\n",
    "        labels_name = None\n",
    "        \n",
    "    f1 = f1_score(y, y_pred, labels=labels_idx, average='macro')\n",
    "    acc = accuracy_score(y, y_pred)\n",
    "    class_report = classification_report(y, y_pred, labels=labels_idx, target_names=labels_name)\n",
    "\n",
    "    # y_score = pred probabilityes\n",
    "    # fpr, tpr, _ = roc_curve(y_test, y_score)\n",
    "    # roc_display = RocCurveDisplay(fpr=fpr, tpr=tpr).plot()\n",
    "    # cm = multilabel_confusion_matrix(y, y_pred)\n",
    "    cm = confusion_matrix(y, y_pred, normalize='true')\n",
    "    \n",
    "    if plot:\n",
    "        print(f\"f1: {f1}\\nacc: {acc}\\n{class_report}\")\n",
    "        fig, ax = plt.subplots(figsize=(4,7))\n",
    "        cm_disp = ConfusionMatrixDisplay(cm).plot(ax=ax, cmap='Blues', colorbar=False)\n",
    "        c_bar = fig.add_axes([ax.get_position().x1+0.01, ax.get_position().y0, 0.05, ax.get_position().height])\n",
    "        plt.colorbar(cm_disp.im_,  cax=c_bar)\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"f1: {f1}\\nacc: {acc}\\n{class_report}\\n{cm}\")\n",
    "    \n",
    "class PredictionEvaluater(object):\n",
    "\n",
    "    def __init__(self, prediction_set, target_names=None, savepath=None, model_name=None):     \n",
    "\n",
    "        self._labels, self._predictions = prediction_set\n",
    "        \n",
    "        self._target_names = target_names\n",
    "        self.num_labels = len(target_names)\n",
    "        self.label_map = {k:v for k,v in zip(range(self.num_labels), self._target_names)}\n",
    "        print(f\"Number of labels in target_names is {self.num_labels}\")\n",
    "\n",
    "        self.savepath = savepath.joinpath('predictions')\n",
    "        self.savepath.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        self._model_name = model_name if model_name is not None else \"model\"\n",
    "        \n",
    "    def compute_metrics(self, eval_pred, eval_metric=\"accuracy\"):\n",
    "        logits, labels = eval_pred\n",
    "        preds = np.argmax(logits, axis=-1)\n",
    "        metric = evaluate.load(eval_metric)\n",
    "        return metric.compute(predictions=preds, references=labels)\n",
    "    \n",
    "    def append_predictions(self, test_df):\n",
    "        # append prediction and encoded labels to original test data\n",
    "        df = test_df.copy()\n",
    "        df[f\"{self._model_name}_prediction\"] = self._predictions\n",
    "        df[\"annotation\"] = self._labels\n",
    "        if self.savepath is not None:\n",
    "            sub_df = df[[f\"{self._model_name}_prediction\",\"annotation\"]]\n",
    "            sub_df.rename_axis('index').to_csv(self.savepath.joinpath(f\"{self._model_name}_predictions.csv\"))\n",
    "        return df\n",
    "        \n",
    "    def evaluation_report(self, test_df, lang_eval=True):\n",
    "        df = self.append_predictions(test_df)\n",
    "        evaluation_display(df[\"annotation\"], df[f\"{self._model_name}_prediction\"], self.label_map)\n",
    "        # if language evaluation is required\n",
    "        if lang_eval:\n",
    "            for lang, lang_df in df.groupby(\"lang\"):\n",
    "                print(f\"\\nEvaluation for language: {lang}\")\n",
    "                evaluation_display(lang_df[\"annotation\"], lang_df[f\"{self._model_name}_prediction\"], self.label_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ec837-3e56-48ab-9b80-5428adee3b16",
   "metadata": {},
   "source": [
    "## Wrapper \n",
    "<a name=\"wrapper\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d86e791e-5b17-43d4-ad24-ae6fb76098ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "The script for wrapper function to run multilingual_ILI_classification.py\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "import logging as log\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# from reader import EncodedDataset\n",
    "# from preprocessor import DataProcessor\n",
    "# from trainer import hyperparams, ModelTrainer\n",
    "# from evaluater import PredictionEvaluater\n",
    "\n",
    "def getsplitidx(lang_split_idx, key='train_idx'):\n",
    "    idx_list = [v[key] for k,v in lang_split_idx.items()]\n",
    "    idx_list = [i for eachlist in idx_list for i in eachlist]\n",
    "    return idx_list\n",
    "\n",
    "def mlm_evaluation(lang_split_idx, tweets, config, split_path, cache_path, lang, lang_eval, hyperparams=hyperparams, save=False):\n",
    "\n",
    "    # obtain datasplit index\n",
    "    train_idx = getsplitidx(lang_split_idx, key='train_idx')\n",
    "    valid_idx = getsplitidx(lang_split_idx, key='valid_idx')\n",
    "    test_idx = getsplitidx(lang_split_idx, key='test_idx')\n",
    "    print(f\"Distribution of data in train, validation and test splits: {len(train_idx)}, {len(valid_idx)}, {len(test_idx)}\")\n",
    "\n",
    "    test_df = tweets.data.iloc[test_idx]\n",
    "    if save:\n",
    "        test_df.rename_axis('index').to_csv(split_path.joinpath(f\"{split_path.stem}_{lang}.csv\"))\n",
    "        # add target names into config outside of the function\n",
    "        # config['target_names'] = sorted(test_df['final_annotation'].unique().tolist())\n",
    "    \n",
    "    # ensure all parameters for trianing exists\n",
    "    CONFIG = {k.upper():v for k,v in config.items()}\n",
    "    if not all(k in CONFIG.keys() for k in hyperparams):\n",
    "        sys.exit(f\"provide all required hyperparams: {hyperparams}. Received only {CONFIG.keys()}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        # encode the data using the model checkpoint\n",
    "        print(f\"Working with {CONFIG['MODEL_CHECKPOINT']}\")\n",
    "        processor = DataProcessor(CONFIG, return_type_ids=True)\n",
    "        feature_encodings, label_encodings = processor.encoded_data(tweets.data['tweet'], tweets.data['final_annotation'])\n",
    "    \n",
    "        # obtain encoded train, valid and test data as dataset object\n",
    "        encoded_dataset = EncodedDataset(feature_encodings, label_encodings)\n",
    "        train_dataset, valid_dataset, test_dataset = encoded_dataset.splitdata([train_idx, valid_idx, test_idx])\n",
    "        print(f\"Distribution of data splits for {lang} language is {train_dataset.shape}, {valid_dataset.shape}, {test_dataset.shape}\")\n",
    "\n",
    "        trainer = ModelTrainer(CONFIG, train_dataset, valid_dataset, test_dataset, processor.tokenizer(), split_path, cache_path, lang)\n",
    "        model, prediction_set = trainer.train_eval(get_pred=True)\n",
    "        print(f\"\\n{trainer.model_name} trained on {trainer._lang_to_train} languages\")\n",
    "        \n",
    "        # delete wandb and model folder related to this model checkpoint\n",
    "        print(f\"free space by deleting: {cache_path.parent.joinpath('models')}\")\n",
    "        shutil.rmtree(cache_path.parent.joinpath('models'), ignore_errors=True)\n",
    "            \n",
    "        # evaluate on test set\n",
    "        evaluater = PredictionEvaluater(prediction_set, CONFIG['TARGET_NAMES'], split_path, f\"{trainer.model_name}_{lang}\")\n",
    "        evaluater.evaluation_report(test_df, lang_eval)\n",
    "     \n",
    "    except Exception as error:\n",
    "        print(\"An error occurred:\", error)\n",
    "        log.exception('Failed')\n",
    "        pass \n",
    "        \n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(f\"Total execution time to finetune {trainer.model_name} on {trainer._lang_to_train} language(s) is {execution_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ab6589-fbbe-4fd3-a8ab-c60bcb8e6994",
   "metadata": {},
   "source": [
    "## Load Data \n",
    "<a name=\"loaddata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "329fbe23-ba08-42c7-ae8d-33335b5631c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets in data: 4400\n",
      "Distribution of classes in all data final_annotation\n",
      "3. Not Related to ILI or COVID-19 Infection       2492\n",
      "1. Likely ILI infection                           1553\n",
      "4. Ambiguous/Unsure                                238\n",
      "2. Likely COVID-19 Infection (after 2020 only)     117\n",
      "Name: count, dtype: int64\n",
      "Configuration setup read from /gaueko0/users/nmishra/multiling_fludetection/params.tsv\n",
      "Cache in /gaueko0/users/nmishra/multiling_fludetection/.cache\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "The script to run model once the best hyperparameters are identified using classification_wandb.py\n",
    "Update required in final_configs.json \n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "from pathlib import Path \n",
    "import argparse\n",
    "import json\n",
    "import logging as log\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "\n",
    "# from reader import CustomDataset\n",
    "# from wrapper import mlm_evaluation\n",
    "\n",
    "# # args\n",
    "# parser = argparse.ArgumentParser(description=\"Twitter Meta Analysis\")\n",
    "# parser.add_argument(\"--data_file\", type=str, help=\"File name including directory where data resides.\")\n",
    "# parser.add_argument(\"--params_file\", type=str, help=\"File where parameters to run the model are provided.\")\n",
    "# parser.add_argument(\"--output_dir\", type=str, help=\"Directory where output are to be stores.\")\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# DATA_FILE = Path(args.data_file)\n",
    "# PARAMS_FILE = Path(args.params_file)\n",
    "# OUT_PATH = Path(args.output_dir)\n",
    "\n",
    "DATA_FILE = Path(\"/gaueko0/users/nmishra/multiling_fludetection/data/all/alldata.csv\")\n",
    "PARAMS_FILE = Path(\"/gaueko0/users/nmishra/multiling_fludetection/params.tsv\")\n",
    "OUT_PATH = Path(\"/gaueko0/users/nmishra/multiling_fludetection/evalnew\")\n",
    "\n",
    "# read data\n",
    "data_path = DATA_FILE.parent\n",
    "tweets = CustomDataset(DATA_FILE, data_path)\n",
    "print(f\"Number of tweets in data: {tweets.__len__()}\")\n",
    "print(f\"Distribution of classes in all data {tweets.labels.value_counts()}\")\n",
    "\n",
    "# hyperparameters\n",
    "params = pd.read_csv(PARAMS_FILE, sep='\\t')\n",
    "target_names = np.unique(tweets.labels).tolist()\n",
    "# params['split'].apply(ast.literal_eval)\n",
    "print(f\"Configuration setup read from {PARAMS_FILE}\")   \n",
    "\n",
    "# where MLMs are cached\n",
    "cache_path = OUT_PATH.parent.joinpath('.cache')\n",
    "cache_path.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Cache in {cache_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0d4e1c-876e-466c-a951-03b9e7cc4757",
   "metadata": {},
   "source": [
    "## Do Training \n",
    "<a name=\"dotraining\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d8f73d8-ab95-48e9-994a-0108d12453fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data split index from: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2\n",
      "\n",
      "Train using data from all languages\n",
      "{'lang': 'all', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'cardiffnlp/twitter-xlm-roberta-base', 'batch_size': 8, 'epochs': 7, 'learning_rate': 3.571430010972717e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 2640, 880, 880\n",
      "Working with cardiffnlp/twitter-xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'all', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'cardiffnlp/twitter-xlm-roberta-base', 'BATCH_SIZE': 8, 'EPOCHS': 7, 'LEARNING_RATE': 3.571430010972717e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for all language is (2640, 4), (880, 4), (880, 4)\n",
      "4 classes in all language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-all-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='cardiffnlp/twitter-xlm-roberta-base', batch_size=8, epochs=7, learning_rate=3.571430010972717e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 07:41, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.720400</td>\n",
       "      <td>0.689699</td>\n",
       "      <td>0.400502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.531300</td>\n",
       "      <td>0.684544</td>\n",
       "      <td>0.437963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.431100</td>\n",
       "      <td>0.943750</td>\n",
       "      <td>0.445802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>1.027272</td>\n",
       "      <td>0.477503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.227000</td>\n",
       "      <td>1.171391</td>\n",
       "      <td>0.478214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>1.199613</td>\n",
       "      <td>0.508798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>1.280594</td>\n",
       "      <td>0.526703</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-all-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "twitter-xlm-roberta-base trained on all languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.4798927260120708\n",
      "acc: 0.7579545454545454\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.74      0.79      0.77       310\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.08      0.13      0.10        23\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.89      0.82      0.85       499\n",
      "                           4. Ambiguous/Unsure       0.20      0.21      0.20        48\n",
      "\n",
      "                                      accuracy                           0.76       880\n",
      "                                     macro avg       0.48      0.49      0.48       880\n",
      "                                  weighted avg       0.78      0.76      0.77       880\n",
      "\n",
      "[[0.79354839 0.04193548 0.11290323 0.0516129 ]\n",
      " [0.52173913 0.13043478 0.2173913  0.13043478]\n",
      " [0.10220441 0.03607214 0.81763527 0.04408818]\n",
      " [0.45833333 0.0625     0.27083333 0.20833333]]\n",
      "\n",
      "Evaluation for language: de\n",
      "f1: 0.4397044765962963\n",
      "acc: 0.69\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.76      0.79      0.77        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.77      0.69      0.73        93\n",
      "                           4. Ambiguous/Unsure       0.22      0.31      0.26        13\n",
      "\n",
      "                                      accuracy                           0.69       200\n",
      "                                     macro avg       0.44      0.45      0.44       200\n",
      "                                  weighted avg       0.71      0.69      0.70       200\n",
      "\n",
      "[[0.78651685 0.02247191 0.13483146 0.05617978]\n",
      " [0.2        0.         0.8        0.        ]\n",
      " [0.1827957  0.03225806 0.68817204 0.09677419]\n",
      " [0.30769231 0.15384615 0.23076923 0.30769231]]\n",
      "\n",
      "Evaluation for language: en\n",
      "f1: 0.517163504968383\n",
      "acc: 0.75\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.72      0.72      0.72        18\n",
      "3. Not Related to ILI or COVID-19 Infection       0.81      0.85      0.83        20\n",
      "                        4. Ambiguous/Unsure       0.00      0.00      0.00         2\n",
      "\n",
      "                                  micro avg       0.77      0.75      0.76        40\n",
      "                                  macro avg       0.51      0.52      0.52        40\n",
      "                               weighted avg       0.73      0.75      0.74        40\n",
      "\n",
      "[[0.72222222 0.05555556 0.22222222 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.15       0.         0.85       0.        ]\n",
      " [1.         0.         0.         0.        ]]\n",
      "\n",
      "Evaluation for language: es\n",
      "f1: 0.5025906892622958\n",
      "acc: 0.7458333333333333\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.78      0.85      0.81        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.09      0.17      0.12        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.92      0.78      0.84       116\n",
      "                           4. Ambiguous/Unsure       0.25      0.23      0.24        13\n",
      "\n",
      "                                      accuracy                           0.75       240\n",
      "                                     macro avg       0.51      0.51      0.50       240\n",
      "                                  weighted avg       0.78      0.75      0.76       240\n",
      "\n",
      "[[0.84848485 0.06060606 0.04040404 0.05050505]\n",
      " [0.75       0.16666667 0.         0.08333333]\n",
      " [0.0862069  0.11206897 0.77586207 0.02586207]\n",
      " [0.38461538 0.07692308 0.30769231 0.23076923]]\n",
      "\n",
      "Evaluation for language: fr\n",
      "f1: 0.5473732477777394\n",
      "acc: 0.775\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.75      0.81      0.78        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.50      0.25      0.33         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.88      0.84      0.86       103\n",
      "                           4. Ambiguous/Unsure       0.21      0.21      0.21        14\n",
      "\n",
      "                                      accuracy                           0.78       200\n",
      "                                     macro avg       0.59      0.53      0.55       200\n",
      "                                  weighted avg       0.77      0.78      0.77       200\n",
      "\n",
      "[[0.81012658 0.01265823 0.11392405 0.06329114]\n",
      " [0.25       0.25       0.25       0.25      ]\n",
      " [0.10679612 0.         0.84466019 0.04854369]\n",
      " [0.64285714 0.         0.14285714 0.21428571]]\n",
      "\n",
      "Evaluation for language: it\n",
      "f1: 0.3708672321274018\n",
      "acc: 0.825\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.54      0.60      0.57        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.94      0.90      0.92       167\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00         6\n",
      "\n",
      "                                      accuracy                           0.82       200\n",
      "                                     macro avg       0.37      0.37      0.37       200\n",
      "                                  weighted avg       0.85      0.82      0.84       200\n",
      "\n",
      "[[0.6        0.12       0.24       0.04      ]\n",
      " [0.5        0.         0.         0.5       ]\n",
      " [0.05988024 0.01197605 0.89820359 0.02994012]\n",
      " [0.33333333 0.         0.66666667 0.        ]]\n",
      "Total execution time to finetune twitter-xlm-roberta-base on all language(s) is 482.95130729675293\n",
      "{'lang': 'all', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'jhu-clsp/bernice', 'batch_size': 8, 'epochs': 6, 'learning_rate': 1.9960876362570808e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 2640, 880, 880\n",
      "Working with jhu-clsp/bernice\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'all', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'jhu-clsp/bernice', 'BATCH_SIZE': 8, 'EPOCHS': 6, 'LEARNING_RATE': 1.9960876362570808e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for all language is (2640, 4), (880, 4), (880, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in all language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-all-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='jhu-clsp/bernice', batch_size=8, epochs=6, learning_rate=1.9960876362570808e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1980' max='1980' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1980/1980 06:52, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.707200</td>\n",
       "      <td>0.613383</td>\n",
       "      <td>0.404659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.552300</td>\n",
       "      <td>0.611158</td>\n",
       "      <td>0.412632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.767190</td>\n",
       "      <td>0.432180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.341500</td>\n",
       "      <td>0.830460</td>\n",
       "      <td>0.501196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.265000</td>\n",
       "      <td>0.985996</td>\n",
       "      <td>0.504652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.202600</td>\n",
       "      <td>1.016502</td>\n",
       "      <td>0.521680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-all-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bernice trained on all languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.5121537668758525\n",
      "acc: 0.7806818181818181\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.73      0.79      0.76       310\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.33      0.17      0.23        23\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.88      0.86      0.87       499\n",
      "                           4. Ambiguous/Unsure       0.19      0.19      0.19        48\n",
      "\n",
      "                                      accuracy                           0.78       880\n",
      "                                     macro avg       0.53      0.50      0.51       880\n",
      "                                  weighted avg       0.78      0.78      0.78       880\n",
      "\n",
      "[[0.78709677 0.01612903 0.13548387 0.06129032]\n",
      " [0.56521739 0.17391304 0.17391304 0.08695652]\n",
      " [0.1002004  0.00400802 0.86172345 0.03406814]\n",
      " [0.52083333 0.02083333 0.27083333 0.1875    ]]\n",
      "\n",
      "Evaluation for language: de\n",
      "f1: 0.5129713013092901\n",
      "acc: 0.715\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.74      0.75      0.75        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.33      0.20      0.25         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.77      0.76      0.77        93\n",
      "                           4. Ambiguous/Unsure       0.27      0.31      0.29        13\n",
      "\n",
      "                                      accuracy                           0.71       200\n",
      "                                     macro avg       0.53      0.51      0.51       200\n",
      "                                  weighted avg       0.72      0.71      0.71       200\n",
      "\n",
      "[[0.75280899 0.01123596 0.17977528 0.05617978]\n",
      " [0.2        0.2        0.6        0.        ]\n",
      " [0.17204301 0.         0.76344086 0.06451613]\n",
      " [0.46153846 0.07692308 0.15384615 0.30769231]]\n",
      "\n",
      "Evaluation for language: en\n",
      "f1: 0.5333333333333333\n",
      "acc: 0.775\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.76      0.72      0.74        18\n",
      "3. Not Related to ILI or COVID-19 Infection       0.82      0.90      0.86        20\n",
      "                        4. Ambiguous/Unsure       0.00      0.00      0.00         2\n",
      "\n",
      "                                  micro avg       0.79      0.78      0.78        40\n",
      "                                  macro avg       0.53      0.54      0.53        40\n",
      "                               weighted avg       0.75      0.78      0.76        40\n",
      "\n",
      "[[0.72222222 0.05555556 0.22222222 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.1        0.         0.9        0.        ]\n",
      " [1.         0.         0.         0.        ]]\n",
      "\n",
      "Evaluation for language: es\n",
      "f1: 0.5206880322979395\n",
      "acc: 0.7666666666666667\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.76      0.81      0.78        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.29      0.17      0.21        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.86      0.85      0.86       116\n",
      "                           4. Ambiguous/Unsure       0.23      0.23      0.23        13\n",
      "\n",
      "                                      accuracy                           0.77       240\n",
      "                                     macro avg       0.53      0.51      0.52       240\n",
      "                                  weighted avg       0.76      0.77      0.76       240\n",
      "\n",
      "[[0.80808081 0.03030303 0.1010101  0.06060606]\n",
      " [0.66666667 0.16666667 0.08333333 0.08333333]\n",
      " [0.10344828 0.01724138 0.85344828 0.02586207]\n",
      " [0.38461538 0.         0.38461538 0.23076923]]\n",
      "\n",
      "Evaluation for language: fr\n",
      "f1: 0.5425905764229118\n",
      "acc: 0.765\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.74      0.82      0.78        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       1.00      0.25      0.40         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.89      0.83      0.86       103\n",
      "                           4. Ambiguous/Unsure       0.12      0.14      0.13        14\n",
      "\n",
      "                                      accuracy                           0.77       200\n",
      "                                     macro avg       0.69      0.51      0.54       200\n",
      "                                  weighted avg       0.78      0.77      0.77       200\n",
      "\n",
      "[[0.82278481 0.         0.08860759 0.08860759]\n",
      " [0.5        0.25       0.         0.25      ]\n",
      " [0.11650485 0.         0.82524272 0.05825243]\n",
      " [0.64285714 0.         0.21428571 0.14285714]]\n",
      "\n",
      "Evaluation for language: it\n",
      "f1: 0.4031124497991968\n",
      "acc: 0.88\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.59      0.76      0.67        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.95      0.94      0.95       167\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00         6\n",
      "\n",
      "                                      accuracy                           0.88       200\n",
      "                                     macro avg       0.39      0.43      0.40       200\n",
      "                                  weighted avg       0.87      0.88      0.87       200\n",
      "\n",
      "[[0.76       0.         0.2        0.04      ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.04790419 0.         0.94011976 0.01197605]\n",
      " [0.5        0.         0.5        0.        ]]\n",
      "Total execution time to finetune bernice on all language(s) is 425.9545588493347\n",
      "{'lang': 'all', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'bert-base-multilingual-uncased', 'batch_size': 32, 'epochs': 10, 'learning_rate': 4.714003352774175e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 2640, 880, 880\n",
      "Working with bert-base-multilingual-uncased\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'all', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'bert-base-multilingual-uncased', 'BATCH_SIZE': 32, 'EPOCHS': 10, 'LEARNING_RATE': 4.714003352774175e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for all language is (2640, 4), (880, 4), (880, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in all language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-all-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='bert-base-multilingual-uncased', batch_size=32, epochs=10, learning_rate=4.714003352774175e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='747' max='830' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [747/830 06:06 < 00:40, 2.03 it/s, Epoch 9/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.754878</td>\n",
       "      <td>0.373203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.599700</td>\n",
       "      <td>0.680295</td>\n",
       "      <td>0.387319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.468600</td>\n",
       "      <td>0.764457</td>\n",
       "      <td>0.387798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.347000</td>\n",
       "      <td>0.907304</td>\n",
       "      <td>0.416787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.268100</td>\n",
       "      <td>0.943916</td>\n",
       "      <td>0.463397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.214500</td>\n",
       "      <td>1.095098</td>\n",
       "      <td>0.499128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>1.256063</td>\n",
       "      <td>0.466335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.098000</td>\n",
       "      <td>1.366857</td>\n",
       "      <td>0.483950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>1.295521</td>\n",
       "      <td>0.476338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-all-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bert-base-multilingual-uncased trained on all languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.459322938942049\n",
      "acc: 0.7454545454545455\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.68      0.80      0.74       310\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.22      0.22      0.22        23\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.85      0.80      0.83       499\n",
      "                           4. Ambiguous/Unsure       0.09      0.04      0.06        48\n",
      "\n",
      "                                      accuracy                           0.75       880\n",
      "                                     macro avg       0.46      0.47      0.46       880\n",
      "                                  weighted avg       0.73      0.75      0.74       880\n",
      "\n",
      "[[0.8        0.01612903 0.1483871  0.03548387]\n",
      " [0.39130435 0.2173913  0.34782609 0.04347826]\n",
      " [0.16032064 0.01803607 0.80360721 0.01803607]\n",
      " [0.5625     0.08333333 0.3125     0.04166667]]\n",
      "\n",
      "Evaluation for language: de\n",
      "f1: 0.4344418739155581\n",
      "acc: 0.675\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.67      0.76      0.72        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.25      0.40      0.31         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.73      0.70      0.71        93\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        13\n",
      "\n",
      "                                      accuracy                           0.68       200\n",
      "                                     macro avg       0.41      0.47      0.43       200\n",
      "                                  weighted avg       0.65      0.68      0.66       200\n",
      "\n",
      "[[0.76404494 0.02247191 0.20224719 0.01123596]\n",
      " [0.2        0.4        0.4        0.        ]\n",
      " [0.2688172  0.02150538 0.69892473 0.01075269]\n",
      " [0.53846154 0.15384615 0.30769231 0.        ]]\n",
      "\n",
      "Evaluation for language: en\n",
      "f1: 0.7092592592592593\n",
      "acc: 0.8\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.78      0.78      0.78        18\n",
      "3. Not Related to ILI or COVID-19 Infection       0.85      0.85      0.85        20\n",
      "                        4. Ambiguous/Unsure       0.50      0.50      0.50         2\n",
      "\n",
      "                                   accuracy                           0.80        40\n",
      "                                  macro avg       0.71      0.71      0.71        40\n",
      "                               weighted avg       0.80      0.80      0.80        40\n",
      "\n",
      "[[0.77777778 0.16666667 0.05555556]\n",
      " [0.15       0.85       0.        ]\n",
      " [0.5        0.         0.5       ]]\n",
      "\n",
      "Evaluation for language: es\n",
      "f1: 0.46202898550724636\n",
      "acc: 0.7333333333333333\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.76      0.83      0.79        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.15      0.17      0.16        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.83      0.78      0.81       116\n",
      "                           4. Ambiguous/Unsure       0.10      0.08      0.09        13\n",
      "\n",
      "                                      accuracy                           0.73       240\n",
      "                                     macro avg       0.46      0.46      0.46       240\n",
      "                                  weighted avg       0.73      0.73      0.73       240\n",
      "\n",
      "[[0.82828283 0.03030303 0.09090909 0.05050505]\n",
      " [0.41666667 0.16666667 0.33333333 0.08333333]\n",
      " [0.12931034 0.06034483 0.78448276 0.02586207]\n",
      " [0.46153846 0.07692308 0.38461538 0.07692308]]\n",
      "\n",
      "Evaluation for language: fr\n",
      "f1: 0.48754253883153675\n",
      "acc: 0.765\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.69      0.86      0.76        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.50      0.25      0.33         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.89      0.82      0.85       103\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        14\n",
      "\n",
      "                                      accuracy                           0.77       200\n",
      "                                     macro avg       0.52      0.48      0.49       200\n",
      "                                  weighted avg       0.74      0.77      0.75       200\n",
      "\n",
      "[[0.86075949 0.         0.08860759 0.05063291]\n",
      " [0.5        0.25       0.25       0.        ]\n",
      " [0.17475728 0.         0.81553398 0.00970874]\n",
      " [0.78571429 0.07142857 0.14285714 0.        ]]\n",
      "\n",
      "Evaluation for language: it\n",
      "f1: 0.34852258852258855\n",
      "acc: 0.8\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.42      0.64      0.51        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.91      0.86      0.89       167\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00         6\n",
      "\n",
      "                                      accuracy                           0.80       200\n",
      "                                     macro avg       0.33      0.38      0.35       200\n",
      "                                  weighted avg       0.81      0.80      0.80       200\n",
      "\n",
      "[[0.64       0.         0.36       0.        ]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.11377246 0.         0.86227545 0.0239521 ]\n",
      " [0.33333333 0.         0.66666667 0.        ]]\n",
      "Total execution time to finetune bert-base-multilingual-uncased on all language(s) is 377.2541081905365\n",
      "{'lang': 'all', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'microsoft/mdeberta-v3-base', 'batch_size': 16, 'epochs': 10, 'learning_rate': 2.2015563091912367e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 2640, 880, 880\n",
      "Working with microsoft/mdeberta-v3-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'all', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'microsoft/mdeberta-v3-base', 'BATCH_SIZE': 16, 'EPOCHS': 10, 'LEARNING_RATE': 2.2015563091912367e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for all language is (2640, 4), (880, 4), (880, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in all language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-all-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='microsoft/mdeberta-v3-base', batch_size=16, epochs=10, learning_rate=2.2015563091912367e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1650' max='1650' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1650/1650 11:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.780700</td>\n",
       "      <td>0.658797</td>\n",
       "      <td>0.403842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.582500</td>\n",
       "      <td>0.609130</td>\n",
       "      <td>0.404630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.490300</td>\n",
       "      <td>0.637993</td>\n",
       "      <td>0.410753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.405900</td>\n",
       "      <td>0.740199</td>\n",
       "      <td>0.436017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>0.762898</td>\n",
       "      <td>0.482017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.279800</td>\n",
       "      <td>0.859788</td>\n",
       "      <td>0.473248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>0.922791</td>\n",
       "      <td>0.513800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.172800</td>\n",
       "      <td>0.941020</td>\n",
       "      <td>0.510304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.136000</td>\n",
       "      <td>1.029872</td>\n",
       "      <td>0.513877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.119600</td>\n",
       "      <td>1.026103</td>\n",
       "      <td>0.518787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-all-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "mdeberta-v3-base trained on all languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.5081723537379206\n",
      "acc: 0.7761363636363636\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.75      0.77      0.76       310\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.18      0.13      0.15        23\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.87      0.86      0.86       499\n",
      "                           4. Ambiguous/Unsure       0.25      0.27      0.26        48\n",
      "\n",
      "                                      accuracy                           0.78       880\n",
      "                                     macro avg       0.51      0.51      0.51       880\n",
      "                                  weighted avg       0.78      0.78      0.78       880\n",
      "\n",
      "[[0.77096774 0.02580645 0.14193548 0.06129032]\n",
      " [0.39130435 0.13043478 0.30434783 0.17391304]\n",
      " [0.10420842 0.00400802 0.85771543 0.03406814]\n",
      " [0.35416667 0.08333333 0.29166667 0.27083333]]\n",
      "\n",
      "Evaluation for language: de\n",
      "f1: 0.4335106382978724\n",
      "acc: 0.68\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.74      0.71      0.72        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.73      0.74      0.73        93\n",
      "                           4. Ambiguous/Unsure       0.25      0.31      0.28        13\n",
      "\n",
      "                                      accuracy                           0.68       200\n",
      "                                     macro avg       0.43      0.44      0.43       200\n",
      "                                  weighted avg       0.68      0.68      0.68       200\n",
      "\n",
      "[[0.70786517 0.03370787 0.21348315 0.04494382]\n",
      " [0.2        0.         0.8        0.        ]\n",
      " [0.17204301 0.         0.74193548 0.08602151]\n",
      " [0.38461538 0.07692308 0.23076923 0.30769231]]\n",
      "\n",
      "Evaluation for language: en\n",
      "f1: 0.5704607046070461\n",
      "acc: 0.825\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.83      0.83      0.83        18\n",
      "3. Not Related to ILI or COVID-19 Infection       0.86      0.90      0.88        20\n",
      "                        4. Ambiguous/Unsure       0.00      0.00      0.00         2\n",
      "\n",
      "                                  micro avg       0.85      0.82      0.84        40\n",
      "                                  macro avg       0.56      0.58      0.57        40\n",
      "                               weighted avg       0.80      0.82      0.81        40\n",
      "\n",
      "[[0.83333333 0.05555556 0.11111111 0.        ]\n",
      " [0.         0.         0.         0.        ]\n",
      " [0.1        0.         0.9        0.        ]\n",
      " [0.5        0.         0.5        0.        ]]\n",
      "\n",
      "Evaluation for language: es\n",
      "f1: 0.5472607655502392\n",
      "acc: 0.7666666666666667\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.78      0.80      0.79        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.30      0.25      0.27        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.88      0.84      0.86       116\n",
      "                           4. Ambiguous/Unsure       0.24      0.31      0.27        13\n",
      "\n",
      "                                      accuracy                           0.77       240\n",
      "                                     macro avg       0.55      0.55      0.55       240\n",
      "                                  weighted avg       0.77      0.77      0.77       240\n",
      "\n",
      "[[0.7979798  0.03030303 0.08080808 0.09090909]\n",
      " [0.5        0.25       0.16666667 0.08333333]\n",
      " [0.11206897 0.01724138 0.84482759 0.02586207]\n",
      " [0.23076923 0.15384615 0.30769231 0.30769231]]\n",
      "\n",
      "Evaluation for language: fr\n",
      "f1: 0.502786169360979\n",
      "acc: 0.795\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.79      0.86      0.82        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.90      0.83      0.86       103\n",
      "                           4. Ambiguous/Unsure       0.29      0.36      0.32        14\n",
      "\n",
      "                                      accuracy                           0.80       200\n",
      "                                     macro avg       0.50      0.51      0.50       200\n",
      "                                  weighted avg       0.79      0.80      0.79       200\n",
      "\n",
      "[[0.86075949 0.         0.06329114 0.07594937]\n",
      " [0.25       0.         0.25       0.5       ]\n",
      " [0.12621359 0.         0.83495146 0.03883495]\n",
      " [0.28571429 0.07142857 0.28571429 0.35714286]]\n",
      "\n",
      "Evaluation for language: it\n",
      "f1: 0.368246336996337\n",
      "acc: 0.855\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.52      0.56      0.54        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.93      0.94      0.93       167\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00         6\n",
      "\n",
      "                                      accuracy                           0.85       200\n",
      "                                     macro avg       0.36      0.38      0.37       200\n",
      "                                  weighted avg       0.84      0.85      0.85       200\n",
      "\n",
      "[[0.56       0.04       0.4        0.        ]\n",
      " [0.5        0.         0.         0.5       ]\n",
      " [0.04790419 0.         0.94011976 0.01197605]\n",
      " [0.66666667 0.         0.33333333 0.        ]]\n",
      "Total execution time to finetune mdeberta-v3-base on all language(s) is 682.815851688385\n",
      "{'lang': 'all', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'xlm-roberta-base', 'batch_size': 16, 'epochs': 8, 'learning_rate': 4.129082702898313e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 2640, 880, 880\n",
      "Working with xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'all', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'xlm-roberta-base', 'BATCH_SIZE': 16, 'EPOCHS': 8, 'LEARNING_RATE': 4.129082702898313e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for all language is (2640, 4), (880, 4), (880, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in all language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-all-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='xlm-roberta-base', batch_size=16, epochs=8, learning_rate=4.129082702898313e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1320' max='1320' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1320/1320 08:24, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.823000</td>\n",
       "      <td>0.796330</td>\n",
       "      <td>0.384125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.693392</td>\n",
       "      <td>0.404646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.559500</td>\n",
       "      <td>0.818553</td>\n",
       "      <td>0.398558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.468000</td>\n",
       "      <td>0.804479</td>\n",
       "      <td>0.400163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.799781</td>\n",
       "      <td>0.439727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.322500</td>\n",
       "      <td>0.871129</td>\n",
       "      <td>0.446703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.249100</td>\n",
       "      <td>1.085259</td>\n",
       "      <td>0.487868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.201100</td>\n",
       "      <td>1.093572</td>\n",
       "      <td>0.468153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-all-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "xlm-roberta-base trained on all languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.4976210163721508\n",
      "acc: 0.7647727272727273\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.74      0.74      0.74       310\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.29      0.09      0.13        23\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.86      0.86      0.86       499\n",
      "                           4. Ambiguous/Unsure       0.22      0.31      0.26        48\n",
      "\n",
      "                                      accuracy                           0.76       880\n",
      "                                     macro avg       0.53      0.50      0.50       880\n",
      "                                  weighted avg       0.77      0.76      0.76       880\n",
      "\n",
      "[[0.73870968 0.00322581 0.17096774 0.08709677]\n",
      " [0.39130435 0.08695652 0.34782609 0.17391304]\n",
      " [0.09418838 0.00601202 0.85571142 0.04408818]\n",
      " [0.47916667 0.02083333 0.1875     0.3125    ]]\n",
      "\n",
      "Evaluation for language: de\n",
      "f1: 0.44336047651582017\n",
      "acc: 0.71\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.78      0.72      0.75        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.74      0.80      0.77        93\n",
      "                           4. Ambiguous/Unsure       0.22      0.31      0.26        13\n",
      "\n",
      "                                      accuracy                           0.71       200\n",
      "                                     macro avg       0.44      0.46      0.44       200\n",
      "                                  weighted avg       0.71      0.71      0.71       200\n",
      "\n",
      "[[0.71910112 0.         0.20224719 0.07865169]\n",
      " [0.2        0.         0.8        0.        ]\n",
      " [0.12903226 0.         0.79569892 0.07526882]\n",
      " [0.38461538 0.         0.30769231 0.30769231]]\n",
      "\n",
      "Evaluation for language: en\n",
      "f1: 0.4921373200442967\n",
      "acc: 0.725\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.71      0.67      0.69        18\n",
      "3. Not Related to ILI or COVID-19 Infection       0.74      0.85      0.79        20\n",
      "                        4. Ambiguous/Unsure       0.00      0.00      0.00         2\n",
      "\n",
      "                                   accuracy                           0.73        40\n",
      "                                  macro avg       0.48      0.51      0.49        40\n",
      "                               weighted avg       0.69      0.72      0.70        40\n",
      "\n",
      "[[0.66666667 0.33333333 0.        ]\n",
      " [0.15       0.85       0.        ]\n",
      " [1.         0.         0.        ]]\n",
      "\n",
      "Evaluation for language: es\n",
      "f1: 0.5377846270184364\n",
      "acc: 0.7625\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.80      0.77      0.78        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.40      0.17      0.24        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.86      0.86      0.86       116\n",
      "                           4. Ambiguous/Unsure       0.21      0.38      0.27        13\n",
      "\n",
      "                                      accuracy                           0.76       240\n",
      "                                     macro avg       0.57      0.55      0.54       240\n",
      "                                  weighted avg       0.78      0.76      0.77       240\n",
      "\n",
      "[[0.76767677 0.01010101 0.12121212 0.1010101 ]\n",
      " [0.5        0.16666667 0.08333333 0.25      ]\n",
      " [0.07758621 0.00862069 0.86206897 0.05172414]\n",
      " [0.30769231 0.07692308 0.23076923 0.38461538]]\n",
      "\n",
      "Evaluation for language: fr\n",
      "f1: 0.4619733708690764\n",
      "acc: 0.755\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.74      0.78      0.76        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.89      0.83      0.86       103\n",
      "                           4. Ambiguous/Unsure       0.19      0.29      0.23        14\n",
      "\n",
      "                                      accuracy                           0.76       200\n",
      "                                     macro avg       0.46      0.47      0.46       200\n",
      "                                  weighted avg       0.77      0.76      0.76       200\n",
      "\n",
      "[[0.78481013 0.         0.10126582 0.11392405]\n",
      " [0.25       0.         0.5        0.25      ]\n",
      " [0.10679612 0.         0.82524272 0.06796117]\n",
      " [0.71428571 0.         0.         0.28571429]]\n",
      "\n",
      "Evaluation for language: it\n",
      "f1: 0.456060606060606\n",
      "acc: 0.84\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.50      0.60      0.55        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.93      0.90      0.92       167\n",
      "                           4. Ambiguous/Unsure       0.40      0.33      0.36         6\n",
      "\n",
      "                                      accuracy                           0.84       200\n",
      "                                     macro avg       0.46      0.46      0.46       200\n",
      "                                  weighted avg       0.85      0.84      0.84       200\n",
      "\n",
      "[[0.6        0.         0.36       0.04      ]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.07185629 0.01197605 0.90419162 0.01197605]\n",
      " [0.33333333 0.         0.33333333 0.33333333]]\n",
      "Total execution time to finetune xlm-roberta-base on all language(s) is 519.2733769416809\n",
      "\n",
      "Train using data from de languages\n",
      "{'lang': 'de', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'cardiffnlp/twitter-xlm-roberta-base', 'batch_size': 32, 'epochs': 6, 'learning_rate': 6.303128537215267e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with cardiffnlp/twitter-xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'de', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'cardiffnlp/twitter-xlm-roberta-base', 'BATCH_SIZE': 32, 'EPOCHS': 6, 'LEARNING_RATE': 6.303128537215267e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for de language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in de language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-de-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='cardiffnlp/twitter-xlm-roberta-base', batch_size=32, epochs=6, learning_rate=6.303128537215267e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 05:04, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.029800</td>\n",
       "      <td>0.928089</td>\n",
       "      <td>0.313727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.906100</td>\n",
       "      <td>0.870404</td>\n",
       "      <td>0.368920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.784400</td>\n",
       "      <td>0.886828</td>\n",
       "      <td>0.371000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.678500</td>\n",
       "      <td>0.849672</td>\n",
       "      <td>0.366600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.593100</td>\n",
       "      <td>0.876039</td>\n",
       "      <td>0.366675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.522700</td>\n",
       "      <td>0.895525</td>\n",
       "      <td>0.379856</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-de-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "twitter-xlm-roberta-base trained on de languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.35286275803303924\n",
      "acc: 0.675\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.65      0.82      0.73        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.70      0.67      0.69        93\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        13\n",
      "\n",
      "                                      accuracy                           0.68       200\n",
      "                                     macro avg       0.34      0.37      0.35       200\n",
      "                                  weighted avg       0.62      0.68      0.64       200\n",
      "\n",
      "[[0.82022472 0.         0.17977528 0.        ]\n",
      " [0.4        0.         0.6        0.        ]\n",
      " [0.33333333 0.         0.66666667 0.        ]\n",
      " [0.46153846 0.         0.53846154 0.        ]]\n",
      "Total execution time to finetune twitter-xlm-roberta-base on de language(s) is 315.85665822029114\n",
      "{'lang': 'de', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'jhu-clsp/bernice', 'batch_size': 32, 'epochs': 5, 'learning_rate': 1.931835053890701e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with jhu-clsp/bernice\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'de', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'jhu-clsp/bernice', 'BATCH_SIZE': 32, 'EPOCHS': 5, 'LEARNING_RATE': 1.931835053890701e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for de language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in de language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-de-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='jhu-clsp/bernice', batch_size=32, epochs=5, learning_rate=1.931835053890701e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='95' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [95/95 03:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.969300</td>\n",
       "      <td>0.835027</td>\n",
       "      <td>0.356207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.815800</td>\n",
       "      <td>0.816125</td>\n",
       "      <td>0.365919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.725200</td>\n",
       "      <td>0.848576</td>\n",
       "      <td>0.372958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.695700</td>\n",
       "      <td>0.813648</td>\n",
       "      <td>0.363857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.671900</td>\n",
       "      <td>0.809641</td>\n",
       "      <td>0.379391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-de-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bernice trained on de languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.3766845804051261\n",
      "acc: 0.72\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.67      0.88      0.76        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.79      0.71      0.75        93\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        13\n",
      "\n",
      "                                      accuracy                           0.72       200\n",
      "                                     macro avg       0.36      0.40      0.38       200\n",
      "                                  weighted avg       0.66      0.72      0.69       200\n",
      "\n",
      "[[0.87640449 0.         0.12359551 0.        ]\n",
      " [0.4        0.         0.6        0.        ]\n",
      " [0.29032258 0.         0.70967742 0.        ]\n",
      " [0.69230769 0.         0.30769231 0.        ]]\n",
      "Total execution time to finetune bernice on de language(s) is 231.26459646224976\n",
      "{'lang': 'de', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'bert-base-multilingual-uncased', 'batch_size': 16, 'epochs': 3, 'learning_rate': 1.760419522770641e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with bert-base-multilingual-uncased\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'de', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'bert-base-multilingual-uncased', 'BATCH_SIZE': 16, 'EPOCHS': 3, 'LEARNING_RATE': 1.760419522770641e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for de language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in de language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-de-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='bert-base-multilingual-uncased', batch_size=16, epochs=3, learning_rate=1.760419522770641e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 01:45, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.017600</td>\n",
       "      <td>0.834531</td>\n",
       "      <td>0.368878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.803800</td>\n",
       "      <td>0.823919</td>\n",
       "      <td>0.374184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.729100</td>\n",
       "      <td>0.828555</td>\n",
       "      <td>0.369429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-de-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bert-base-multilingual-uncased trained on de languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.36629330984946473\n",
      "acc: 0.7\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.66      0.84      0.74        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.76      0.70      0.73        93\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        13\n",
      "\n",
      "                                      accuracy                           0.70       200\n",
      "                                     macro avg       0.35      0.39      0.37       200\n",
      "                                  weighted avg       0.64      0.70      0.67       200\n",
      "\n",
      "[[0.84269663 0.         0.15730337 0.        ]\n",
      " [0.4        0.         0.6        0.        ]\n",
      " [0.30107527 0.         0.69892473 0.        ]\n",
      " [0.69230769 0.         0.30769231 0.        ]]\n",
      "Total execution time to finetune bert-base-multilingual-uncased on de language(s) is 114.35963177680969\n",
      "{'lang': 'de', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'microsoft/mdeberta-v3-base', 'batch_size': 32, 'epochs': 6, 'learning_rate': 1.846007640647933e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with microsoft/mdeberta-v3-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'de', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'microsoft/mdeberta-v3-base', 'BATCH_SIZE': 32, 'EPOCHS': 6, 'LEARNING_RATE': 1.846007640647933e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for de language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in de language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-de-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='microsoft/mdeberta-v3-base', batch_size=32, epochs=6, learning_rate=1.846007640647933e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 04:43, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.157300</td>\n",
       "      <td>0.970841</td>\n",
       "      <td>0.299670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.939900</td>\n",
       "      <td>0.874204</td>\n",
       "      <td>0.361381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.858800</td>\n",
       "      <td>0.831795</td>\n",
       "      <td>0.366767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.801700</td>\n",
       "      <td>0.809946</td>\n",
       "      <td>0.366950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.751900</td>\n",
       "      <td>0.824134</td>\n",
       "      <td>0.361454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.718500</td>\n",
       "      <td>0.809338</td>\n",
       "      <td>0.377310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-de-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "mdeberta-v3-base trained on de languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.37434554973822\n",
      "acc: 0.715\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.71      0.81      0.75        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.72      0.76      0.74        93\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        13\n",
      "\n",
      "                                      accuracy                           0.71       200\n",
      "                                     macro avg       0.36      0.39      0.37       200\n",
      "                                  weighted avg       0.65      0.71      0.68       200\n",
      "\n",
      "[[0.80898876 0.         0.19101124 0.        ]\n",
      " [0.4        0.         0.6        0.        ]\n",
      " [0.23655914 0.         0.76344086 0.        ]\n",
      " [0.46153846 0.         0.53846154 0.        ]]\n",
      "Total execution time to finetune mdeberta-v3-base on de language(s) is 293.9917731285095\n",
      "{'lang': 'de', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'xlm-roberta-base', 'batch_size': 32, 'epochs': 6, 'learning_rate': 2.216664432392652e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'de', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'xlm-roberta-base', 'BATCH_SIZE': 32, 'EPOCHS': 6, 'LEARNING_RATE': 2.216664432392652e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for de language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in de language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-de-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='xlm-roberta-base', batch_size=32, epochs=6, learning_rate=2.216664432392652e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='114' max='114' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [114/114 05:08, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.141600</td>\n",
       "      <td>0.963592</td>\n",
       "      <td>0.304526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.944100</td>\n",
       "      <td>0.887931</td>\n",
       "      <td>0.315360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.799150</td>\n",
       "      <td>0.371807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.793200</td>\n",
       "      <td>0.838556</td>\n",
       "      <td>0.360831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.770800</td>\n",
       "      <td>0.827970</td>\n",
       "      <td>0.363758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.807485</td>\n",
       "      <td>0.377155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-de-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "xlm-roberta-base trained on de languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.3743043561696412\n",
      "acc: 0.715\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.70      0.79      0.74        89\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         5\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.73      0.78      0.76        93\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        13\n",
      "\n",
      "                                      accuracy                           0.71       200\n",
      "                                     macro avg       0.36      0.39      0.37       200\n",
      "                                  weighted avg       0.65      0.71      0.68       200\n",
      "\n",
      "[[0.78651685 0.         0.21348315 0.        ]\n",
      " [0.4        0.         0.6        0.        ]\n",
      " [0.21505376 0.         0.78494624 0.        ]\n",
      " [0.61538462 0.         0.38461538 0.        ]]\n",
      "Total execution time to finetune xlm-roberta-base on de language(s) is 318.9323146343231\n",
      "\n",
      "Train using data from en languages\n",
      "{'lang': 'en', 'split': '0.6,0.2,0.2', 'n_labels': 3, 'max_len': 128, 'model_checkpoint': 'cardiffnlp/twitter-xlm-roberta-base', 'batch_size': 32, 'epochs': 6, 'learning_rate': 0.000148748398571, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 120, 40, 40\n",
      "Working with cardiffnlp/twitter-xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'en', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 3, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'cardiffnlp/twitter-xlm-roberta-base', 'BATCH_SIZE': 32, 'EPOCHS': 6, 'LEARNING_RATE': 0.000148748398571, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for en language is (120, 4), (40, 4), (40, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in en language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-en-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='cardiffnlp/twitter-xlm-roberta-base', batch_size=32, epochs=6, learning_rate=0.000148748398571)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 04:37, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.140800</td>\n",
       "      <td>0.815792</td>\n",
       "      <td>0.478632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.767900</td>\n",
       "      <td>0.706175</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.525500</td>\n",
       "      <td>0.758964</td>\n",
       "      <td>0.495681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>0.708006</td>\n",
       "      <td>0.529915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.228600</td>\n",
       "      <td>0.777931</td>\n",
       "      <td>0.511185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>0.773696</td>\n",
       "      <td>0.512478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-en-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "twitter-xlm-roberta-base trained on en languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.5464912280701754\n",
      "acc: 0.8\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.75      0.83      0.79        18\n",
      "3. Not Related to ILI or COVID-19 Infection       0.85      0.85      0.85        20\n",
      "                        4. Ambiguous/Unsure       0.00      0.00      0.00         2\n",
      "\n",
      "                                   accuracy                           0.80        40\n",
      "                                  macro avg       0.53      0.56      0.55        40\n",
      "                               weighted avg       0.76      0.80      0.78        40\n",
      "\n",
      "[[0.83333333 0.16666667 0.        ]\n",
      " [0.15       0.85       0.        ]\n",
      " [1.         0.         0.        ]]\n",
      "Total execution time to finetune twitter-xlm-roberta-base on en language(s) is 289.57843494415283\n",
      "{'lang': 'en', 'split': '0.6,0.2,0.2', 'n_labels': 3, 'max_len': 128, 'model_checkpoint': 'jhu-clsp/bernice', 'batch_size': 16, 'epochs': 2, 'learning_rate': 0.0001038648882532, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 120, 40, 40\n",
      "Working with jhu-clsp/bernice\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'en', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 3, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'jhu-clsp/bernice', 'BATCH_SIZE': 16, 'EPOCHS': 2, 'LEARNING_RATE': 0.0001038648882532, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for en language is (120, 4), (40, 4), (40, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in en language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-en-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='jhu-clsp/bernice', batch_size=16, epochs=2, learning_rate=0.0001038648882532)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16/16 01:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.996700</td>\n",
       "      <td>0.819641</td>\n",
       "      <td>0.474074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.750100</td>\n",
       "      <td>0.744547</td>\n",
       "      <td>0.474074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-en-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bernice trained on en languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.526688815060908\n",
      "acc: 0.775\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.76      0.72      0.74        18\n",
      "3. Not Related to ILI or COVID-19 Infection       0.78      0.90      0.84        20\n",
      "                        4. Ambiguous/Unsure       0.00      0.00      0.00         2\n",
      "\n",
      "                                   accuracy                           0.78        40\n",
      "                                  macro avg       0.52      0.54      0.53        40\n",
      "                               weighted avg       0.74      0.78      0.75        40\n",
      "\n",
      "[[0.72222222 0.27777778 0.        ]\n",
      " [0.1        0.9        0.        ]\n",
      " [1.         0.         0.        ]]\n",
      "Total execution time to finetune bernice on en language(s) is 104.19206547737122\n",
      "{'lang': 'en', 'split': '0.6,0.2,0.2', 'n_labels': 3, 'max_len': 128, 'model_checkpoint': 'bert-base-multilingual-uncased', 'batch_size': 32, 'epochs': 7, 'learning_rate': 0.0001048140505428, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 120, 40, 40\n",
      "Working with bert-base-multilingual-uncased\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'en', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 3, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'bert-base-multilingual-uncased', 'BATCH_SIZE': 32, 'EPOCHS': 7, 'LEARNING_RATE': 0.0001048140505428, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for en language is (120, 4), (40, 4), (40, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in en language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-en-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='bert-base-multilingual-uncased', batch_size=32, epochs=7, learning_rate=0.0001048140505428)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 03:05, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.112600</td>\n",
       "      <td>0.875221</td>\n",
       "      <td>0.320503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.755700</td>\n",
       "      <td>0.730980</td>\n",
       "      <td>0.459259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.676612</td>\n",
       "      <td>0.508021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.337700</td>\n",
       "      <td>0.646902</td>\n",
       "      <td>0.529915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.255000</td>\n",
       "      <td>0.682519</td>\n",
       "      <td>0.529915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.678648</td>\n",
       "      <td>0.512281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.656467</td>\n",
       "      <td>0.529915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-en-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bert-base-multilingual-uncased trained on en languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.5122807017543859\n",
      "acc: 0.75\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.70      0.78      0.74        18\n",
      "3. Not Related to ILI or COVID-19 Infection       0.80      0.80      0.80        20\n",
      "                        4. Ambiguous/Unsure       0.00      0.00      0.00         2\n",
      "\n",
      "                                   accuracy                           0.75        40\n",
      "                                  macro avg       0.50      0.53      0.51        40\n",
      "                               weighted avg       0.72      0.75      0.73        40\n",
      "\n",
      "[[0.77777778 0.22222222 0.        ]\n",
      " [0.2        0.8        0.        ]\n",
      " [1.         0.         0.        ]]\n",
      "Total execution time to finetune bert-base-multilingual-uncased on en language(s) is 194.0251281261444\n",
      "{'lang': 'en', 'split': '0.6,0.2,0.2', 'n_labels': 3, 'max_len': 128, 'model_checkpoint': 'microsoft/mdeberta-v3-base', 'batch_size': 8, 'epochs': 7, 'learning_rate': 6.214702150620456e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 120, 40, 40\n",
      "Working with microsoft/mdeberta-v3-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'en', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 3, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'microsoft/mdeberta-v3-base', 'BATCH_SIZE': 8, 'EPOCHS': 7, 'LEARNING_RATE': 6.214702150620456e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for en language is (120, 4), (40, 4), (40, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in en language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-en-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='microsoft/mdeberta-v3-base', batch_size=8, epochs=7, learning_rate=6.214702150620456e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='105' max='105' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [105/105 05:53, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.042100</td>\n",
       "      <td>0.870699</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>0.826572</td>\n",
       "      <td>0.372327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.715800</td>\n",
       "      <td>0.662797</td>\n",
       "      <td>0.495614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.449900</td>\n",
       "      <td>0.685149</td>\n",
       "      <td>0.529825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.434400</td>\n",
       "      <td>0.616562</td>\n",
       "      <td>0.541752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.604029</td>\n",
       "      <td>0.512415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.210600</td>\n",
       "      <td>0.587469</td>\n",
       "      <td>0.545736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-en-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "mdeberta-v3-base trained on en languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.5291005291005292\n",
      "acc: 0.775\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.78      0.78      0.78        18\n",
      "3. Not Related to ILI or COVID-19 Infection       0.77      0.85      0.81        20\n",
      "                        4. Ambiguous/Unsure       0.00      0.00      0.00         2\n",
      "\n",
      "                                   accuracy                           0.78        40\n",
      "                                  macro avg       0.52      0.54      0.53        40\n",
      "                               weighted avg       0.74      0.78      0.75        40\n",
      "\n",
      "[[0.77777778 0.22222222 0.        ]\n",
      " [0.15       0.85       0.        ]\n",
      " [0.5        0.5        0.        ]]\n",
      "Total execution time to finetune mdeberta-v3-base on en language(s) is 363.59954857826233\n",
      "{'lang': 'en', 'split': '0.6,0.2,0.2', 'n_labels': 3, 'max_len': 128, 'model_checkpoint': 'xlm-roberta-base', 'batch_size': 16, 'epochs': 9, 'learning_rate': 7.64366123017573e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 120, 40, 40\n",
      "Working with xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'en', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 3, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'xlm-roberta-base', 'BATCH_SIZE': 16, 'EPOCHS': 9, 'LEARNING_RATE': 7.64366123017573e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for en language is (120, 4), (40, 4), (40, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in en language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-en-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='xlm-roberta-base', batch_size=16, epochs=9, learning_rate=7.64366123017573e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='40' max='72' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/72 04:09 < 03:30, 0.15 it/s, Epoch 5/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.146200</td>\n",
       "      <td>0.896001</td>\n",
       "      <td>0.293836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.912600</td>\n",
       "      <td>0.830331</td>\n",
       "      <td>0.513228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.855400</td>\n",
       "      <td>0.833710</td>\n",
       "      <td>0.445897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.711700</td>\n",
       "      <td>0.679897</td>\n",
       "      <td>0.492137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.492400</td>\n",
       "      <td>0.677506</td>\n",
       "      <td>0.506063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-en-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "xlm-roberta-base trained on en languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.5108695652173912\n",
      "acc: 0.75\n",
      "                                             precision    recall  f1-score   support\n",
      "\n",
      "                    1. Likely ILI infection       0.64      1.00      0.78        18\n",
      "3. Not Related to ILI or COVID-19 Infection       1.00      0.60      0.75        20\n",
      "                        4. Ambiguous/Unsure       0.00      0.00      0.00         2\n",
      "\n",
      "                                   accuracy                           0.75        40\n",
      "                                  macro avg       0.55      0.53      0.51        40\n",
      "                               weighted avg       0.79      0.75      0.73        40\n",
      "\n",
      "[[1.  0.  0. ]\n",
      " [0.4 0.6 0. ]\n",
      " [1.  0.  0. ]]\n",
      "Total execution time to finetune xlm-roberta-base on en language(s) is 259.76709365844727\n",
      "\n",
      "Train using data from es languages\n",
      "{'lang': 'es', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'cardiffnlp/twitter-xlm-roberta-base', 'batch_size': 8, 'epochs': 4, 'learning_rate': 7.96269320820549e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 720, 240, 240\n",
      "Working with cardiffnlp/twitter-xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'es', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'cardiffnlp/twitter-xlm-roberta-base', 'BATCH_SIZE': 8, 'EPOCHS': 4, 'LEARNING_RATE': 7.96269320820549e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for es language is (720, 4), (240, 4), (240, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in es language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-es-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='cardiffnlp/twitter-xlm-roberta-base', batch_size=8, epochs=4, learning_rate=7.96269320820549e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [360/360 03:20, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.846900</td>\n",
       "      <td>0.659761</td>\n",
       "      <td>0.415786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>0.896962</td>\n",
       "      <td>0.413030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.441000</td>\n",
       "      <td>0.861651</td>\n",
       "      <td>0.429762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.306700</td>\n",
       "      <td>0.971187</td>\n",
       "      <td>0.481389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-es-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "twitter-xlm-roberta-base trained on es languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.479972742986305\n",
      "acc: 0.7541666666666667\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.81      0.86      0.83        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.88      0.78      0.83       116\n",
      "                           4. Ambiguous/Unsure       0.18      0.46      0.26        13\n",
      "\n",
      "                                      accuracy                           0.75       240\n",
      "                                     macro avg       0.47      0.52      0.48       240\n",
      "                                  weighted avg       0.77      0.75      0.76       240\n",
      "\n",
      "[[0.85858586 0.         0.05050505 0.09090909]\n",
      " [0.41666667 0.         0.25       0.33333333]\n",
      " [0.10344828 0.         0.77586207 0.12068966]\n",
      " [0.23076923 0.         0.30769231 0.46153846]]\n",
      "Total execution time to finetune twitter-xlm-roberta-base on es language(s) is 212.4523811340332\n",
      "{'lang': 'es', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'jhu-clsp/bernice', 'batch_size': 32, 'epochs': 10, 'learning_rate': 7.48302766200615e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 720, 240, 240\n",
      "Working with jhu-clsp/bernice\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'es', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'jhu-clsp/bernice', 'BATCH_SIZE': 32, 'EPOCHS': 10, 'LEARNING_RATE': 7.48302766200615e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for es language is (720, 4), (240, 4), (240, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in es language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-es-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='jhu-clsp/bernice', batch_size=32, epochs=10, learning_rate=7.48302766200615e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='230' max='230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [230/230 08:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.798700</td>\n",
       "      <td>0.703530</td>\n",
       "      <td>0.414793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.598400</td>\n",
       "      <td>0.660438</td>\n",
       "      <td>0.425108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.462600</td>\n",
       "      <td>0.738729</td>\n",
       "      <td>0.461911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.280800</td>\n",
       "      <td>0.899517</td>\n",
       "      <td>0.411844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.200300</td>\n",
       "      <td>0.991726</td>\n",
       "      <td>0.529071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.132400</td>\n",
       "      <td>0.892603</td>\n",
       "      <td>0.540339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.964098</td>\n",
       "      <td>0.523959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>1.053349</td>\n",
       "      <td>0.566636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>1.083146</td>\n",
       "      <td>0.579948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>1.126551</td>\n",
       "      <td>0.520382</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-es-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bernice trained on es languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.4922927094920282\n",
      "acc: 0.7458333333333333\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.78      0.74      0.76        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.21      0.33      0.26        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.87      0.87      0.87       116\n",
      "                           4. Ambiguous/Unsure       0.08      0.08      0.08        13\n",
      "\n",
      "                                      accuracy                           0.75       240\n",
      "                                     macro avg       0.49      0.50      0.49       240\n",
      "                                  weighted avg       0.76      0.75      0.75       240\n",
      "\n",
      "[[0.73737374 0.08080808 0.11111111 0.07070707]\n",
      " [0.5        0.33333333 0.08333333 0.08333333]\n",
      " [0.06034483 0.04310345 0.87068966 0.02586207]\n",
      " [0.53846154 0.15384615 0.23076923 0.07692308]]\n",
      "Total execution time to finetune bernice on es language(s) is 508.121958732605\n",
      "{'lang': 'es', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 256, 'model_checkpoint': 'bert-base-multilingual-uncased', 'batch_size': 8, 'epochs': 6, 'learning_rate': 2.7742632399963146e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 720, 240, 240\n",
      "Working with bert-base-multilingual-uncased\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'es', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 256, 'MODEL_CHECKPOINT': 'bert-base-multilingual-uncased', 'BATCH_SIZE': 8, 'EPOCHS': 6, 'LEARNING_RATE': 2.7742632399963146e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Dimensions of encoded features: torch.Size([4400, 164])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for es language is (720, 4), (240, 4), (240, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in es language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-es-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=256, model_checkpoint='bert-base-multilingual-uncased', batch_size=8, epochs=6, learning_rate=2.7742632399963146e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 03:25, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.830500</td>\n",
       "      <td>0.789398</td>\n",
       "      <td>0.381447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.623200</td>\n",
       "      <td>0.644513</td>\n",
       "      <td>0.422769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.493100</td>\n",
       "      <td>0.780122</td>\n",
       "      <td>0.422590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.391200</td>\n",
       "      <td>0.719148</td>\n",
       "      <td>0.524001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.272000</td>\n",
       "      <td>0.913900</td>\n",
       "      <td>0.522999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.186400</td>\n",
       "      <td>0.919595</td>\n",
       "      <td>0.495032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-es-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bert-base-multilingual-uncased trained on es languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.48388761131942815\n",
      "acc: 0.7625\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.81      0.76      0.78        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.25      0.17      0.20        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.78      0.91      0.84       116\n",
      "                           4. Ambiguous/Unsure       0.25      0.08      0.12        13\n",
      "\n",
      "                                      accuracy                           0.76       240\n",
      "                                     macro avg       0.52      0.48      0.48       240\n",
      "                                  weighted avg       0.73      0.76      0.74       240\n",
      "\n",
      "[[0.75757576 0.02020202 0.2020202  0.02020202]\n",
      " [0.33333333 0.16666667 0.41666667 0.08333333]\n",
      " [0.0862069  0.00862069 0.90517241 0.        ]\n",
      " [0.30769231 0.23076923 0.38461538 0.07692308]]\n",
      "Total execution time to finetune bert-base-multilingual-uncased on es language(s) is 214.90666365623474\n",
      "{'lang': 'es', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'microsoft/mdeberta-v3-base', 'batch_size': 8, 'epochs': 6, 'learning_rate': 3.407229021688368e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 720, 240, 240\n",
      "Working with microsoft/mdeberta-v3-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'es', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'microsoft/mdeberta-v3-base', 'BATCH_SIZE': 8, 'EPOCHS': 6, 'LEARNING_RATE': 3.407229021688368e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for es language is (720, 4), (240, 4), (240, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in es language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-es-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='microsoft/mdeberta-v3-base', batch_size=8, epochs=6, learning_rate=3.407229021688368e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='540' max='540' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [540/540 05:30, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.846100</td>\n",
       "      <td>0.660019</td>\n",
       "      <td>0.425224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.634100</td>\n",
       "      <td>0.628733</td>\n",
       "      <td>0.415928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.704086</td>\n",
       "      <td>0.429093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.692092</td>\n",
       "      <td>0.423414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.835954</td>\n",
       "      <td>0.417578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.763887</td>\n",
       "      <td>0.420507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-es-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "mdeberta-v3-base trained on es languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.40194926045646\n",
      "acc: 0.7625\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.75      0.81      0.78        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.77      0.89      0.83       116\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        13\n",
      "\n",
      "                                      accuracy                           0.76       240\n",
      "                                     macro avg       0.38      0.42      0.40       240\n",
      "                                  weighted avg       0.69      0.76      0.72       240\n",
      "\n",
      "[[0.80808081 0.         0.19191919 0.        ]\n",
      " [0.41666667 0.         0.58333333 0.        ]\n",
      " [0.10344828 0.00862069 0.88793103 0.        ]\n",
      " [0.69230769 0.         0.30769231 0.        ]]\n",
      "Total execution time to finetune mdeberta-v3-base on es language(s) is 341.65760803222656\n",
      "{'lang': 'es', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'xlm-roberta-base', 'batch_size': 16, 'epochs': 10, 'learning_rate': 3.032823977759674e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 720, 240, 240\n",
      "Working with xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'es', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'xlm-roberta-base', 'BATCH_SIZE': 16, 'EPOCHS': 10, 'LEARNING_RATE': 3.032823977759674e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for es language is (720, 4), (240, 4), (240, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in es language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-es-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='xlm-roberta-base', batch_size=16, epochs=10, learning_rate=3.032823977759674e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 08:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.994700</td>\n",
       "      <td>0.740398</td>\n",
       "      <td>0.390296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.747600</td>\n",
       "      <td>0.744391</td>\n",
       "      <td>0.389717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.631300</td>\n",
       "      <td>0.649676</td>\n",
       "      <td>0.416020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.497700</td>\n",
       "      <td>0.753618</td>\n",
       "      <td>0.422457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.452100</td>\n",
       "      <td>0.765868</td>\n",
       "      <td>0.423413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.407800</td>\n",
       "      <td>0.776880</td>\n",
       "      <td>0.426414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.291500</td>\n",
       "      <td>0.905793</td>\n",
       "      <td>0.441432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.219300</td>\n",
       "      <td>1.325014</td>\n",
       "      <td>0.409384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.202300</td>\n",
       "      <td>1.047434</td>\n",
       "      <td>0.485983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.173600</td>\n",
       "      <td>1.058876</td>\n",
       "      <td>0.464250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-es-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "xlm-roberta-base trained on es languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.45149993684476447\n",
      "acc: 0.7416666666666667\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.80      0.78      0.79        99\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.13      0.25      0.17        12\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.84      0.84      0.84       116\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        13\n",
      "\n",
      "                                      accuracy                           0.74       240\n",
      "                                     macro avg       0.44      0.47      0.45       240\n",
      "                                  weighted avg       0.75      0.74      0.74       240\n",
      "\n",
      "[[0.77777778 0.08080808 0.11111111 0.03030303]\n",
      " [0.41666667 0.25       0.33333333 0.        ]\n",
      " [0.07758621 0.06034483 0.84482759 0.01724138]\n",
      " [0.38461538 0.38461538 0.23076923 0.        ]]\n",
      "Total execution time to finetune xlm-roberta-base on es language(s) is 497.0987946987152\n",
      "\n",
      "Train using data from fr languages\n",
      "{'lang': 'fr', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 256, 'model_checkpoint': 'cardiffnlp/twitter-xlm-roberta-base', 'batch_size': 8, 'epochs': 4, 'learning_rate': 2.596766847433272e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with cardiffnlp/twitter-xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'fr', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 256, 'MODEL_CHECKPOINT': 'cardiffnlp/twitter-xlm-roberta-base', 'BATCH_SIZE': 8, 'EPOCHS': 4, 'LEARNING_RATE': 2.596766847433272e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Dimensions of encoded features: torch.Size([4400, 160])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for fr language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in fr language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-fr-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=256, model_checkpoint='cardiffnlp/twitter-xlm-roberta-base', batch_size=8, epochs=4, learning_rate=2.596766847433272e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [300/300 03:16, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.872400</td>\n",
       "      <td>0.693124</td>\n",
       "      <td>0.406695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>0.639585</td>\n",
       "      <td>0.406146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.759359</td>\n",
       "      <td>0.401231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.365600</td>\n",
       "      <td>0.782254</td>\n",
       "      <td>0.409177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-fr-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "twitter-xlm-roberta-base trained on fr languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.4123742593358137\n",
      "acc: 0.79\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.71      0.89      0.79        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.86      0.85      0.86       103\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        14\n",
      "\n",
      "                                      accuracy                           0.79       200\n",
      "                                     macro avg       0.39      0.44      0.41       200\n",
      "                                  weighted avg       0.73      0.79      0.75       200\n",
      "\n",
      "[[0.88607595 0.         0.11392405 0.        ]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.14563107 0.         0.85436893 0.        ]\n",
      " [0.78571429 0.         0.21428571 0.        ]]\n",
      "Total execution time to finetune twitter-xlm-roberta-base on fr language(s) is 208.65012884140015\n",
      "{'lang': 'fr', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'jhu-clsp/bernice', 'batch_size': 16, 'epochs': 6, 'learning_rate': 8.106216723781869e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with jhu-clsp/bernice\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'fr', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'jhu-clsp/bernice', 'BATCH_SIZE': 16, 'EPOCHS': 6, 'LEARNING_RATE': 8.106216723781869e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for fr language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in fr language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-fr-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='jhu-clsp/bernice', batch_size=16, epochs=6, learning_rate=8.106216723781869e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='228' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [228/228 05:02, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.799015</td>\n",
       "      <td>0.373198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.733800</td>\n",
       "      <td>0.753206</td>\n",
       "      <td>0.400757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.500400</td>\n",
       "      <td>0.755886</td>\n",
       "      <td>0.396743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.367400</td>\n",
       "      <td>0.995617</td>\n",
       "      <td>0.390587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>1.080687</td>\n",
       "      <td>0.449032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>1.148916</td>\n",
       "      <td>0.430731</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-fr-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bernice trained on fr languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.45317733990147785\n",
      "acc: 0.78\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.74      0.84      0.79        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.88      0.85      0.87       103\n",
      "                           4. Ambiguous/Unsure       0.18      0.14      0.16        14\n",
      "\n",
      "                                      accuracy                           0.78       200\n",
      "                                     macro avg       0.45      0.46      0.45       200\n",
      "                                  weighted avg       0.76      0.78      0.77       200\n",
      "\n",
      "[[0.83544304 0.         0.10126582 0.06329114]\n",
      " [0.75       0.         0.25       0.        ]\n",
      " [0.10679612 0.         0.85436893 0.03883495]\n",
      " [0.64285714 0.         0.21428571 0.14285714]]\n",
      "Total execution time to finetune bernice on fr language(s) is 312.47803354263306\n",
      "{'lang': 'fr', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'bert-base-multilingual-uncased', 'batch_size': 8, 'epochs': 10, 'learning_rate': 1.4333262623697738e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with bert-base-multilingual-uncased\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'fr', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'bert-base-multilingual-uncased', 'BATCH_SIZE': 8, 'EPOCHS': 10, 'LEARNING_RATE': 1.4333262623697738e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for fr language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in fr language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-fr-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='bert-base-multilingual-uncased', batch_size=8, epochs=10, learning_rate=1.4333262623697738e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 04:51, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.916500</td>\n",
       "      <td>0.770221</td>\n",
       "      <td>0.369052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.699800</td>\n",
       "      <td>0.734959</td>\n",
       "      <td>0.389338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.596100</td>\n",
       "      <td>0.748348</td>\n",
       "      <td>0.393076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.509200</td>\n",
       "      <td>0.952224</td>\n",
       "      <td>0.389530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.438900</td>\n",
       "      <td>0.947798</td>\n",
       "      <td>0.396856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.375400</td>\n",
       "      <td>0.986961</td>\n",
       "      <td>0.387959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>0.967719</td>\n",
       "      <td>0.425148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.236500</td>\n",
       "      <td>1.047758</td>\n",
       "      <td>0.404023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.206700</td>\n",
       "      <td>1.101188</td>\n",
       "      <td>0.422254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>1.119583</td>\n",
       "      <td>0.422254</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-fr-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bert-base-multilingual-uncased trained on fr languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.4282846866557274\n",
      "acc: 0.765\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.71      0.81      0.76        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.82      0.85      0.84       103\n",
      "                           4. Ambiguous/Unsure       0.33      0.07      0.12        14\n",
      "\n",
      "                                      accuracy                           0.77       200\n",
      "                                     macro avg       0.47      0.43      0.43       200\n",
      "                                  weighted avg       0.73      0.77      0.74       200\n",
      "\n",
      "[[0.81012658 0.         0.16455696 0.02531646]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.14563107 0.         0.85436893 0.        ]\n",
      " [0.64285714 0.         0.28571429 0.07142857]]\n",
      "Total execution time to finetune bert-base-multilingual-uncased on fr language(s) is 300.5558524131775\n",
      "{'lang': 'fr', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'microsoft/mdeberta-v3-base', 'batch_size': 16, 'epochs': 6, 'learning_rate': 9.84639301079326e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with microsoft/mdeberta-v3-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'fr', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'microsoft/mdeberta-v3-base', 'BATCH_SIZE': 16, 'EPOCHS': 6, 'LEARNING_RATE': 9.84639301079326e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for fr language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in fr language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-fr-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='microsoft/mdeberta-v3-base', batch_size=16, epochs=6, learning_rate=9.84639301079326e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='228' max='228' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [228/228 05:04, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.892300</td>\n",
       "      <td>0.861852</td>\n",
       "      <td>0.342025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.703606</td>\n",
       "      <td>0.391584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.534900</td>\n",
       "      <td>0.920646</td>\n",
       "      <td>0.361323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.414500</td>\n",
       "      <td>0.913368</td>\n",
       "      <td>0.406365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.302200</td>\n",
       "      <td>0.938805</td>\n",
       "      <td>0.464089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.226100</td>\n",
       "      <td>1.057584</td>\n",
       "      <td>0.427003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-fr-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "mdeberta-v3-base trained on fr languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.46972427464408\n",
      "acc: 0.76\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.70      0.89      0.78        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.94      0.76      0.84       103\n",
      "                           4. Ambiguous/Unsure       0.24      0.29      0.26        14\n",
      "\n",
      "                                      accuracy                           0.76       200\n",
      "                                     macro avg       0.47      0.48      0.47       200\n",
      "                                  weighted avg       0.78      0.76      0.76       200\n",
      "\n",
      "[[0.88607595 0.         0.05063291 0.06329114]\n",
      " [0.75       0.         0.25       0.        ]\n",
      " [0.16504854 0.         0.75728155 0.0776699 ]\n",
      " [0.71428571 0.         0.         0.28571429]]\n",
      "Total execution time to finetune mdeberta-v3-base on fr language(s) is 314.9869885444641\n",
      "{'lang': 'fr', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'xlm-roberta-base', 'batch_size': 8, 'epochs': 8, 'learning_rate': 4.2896922812818176e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'fr', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'xlm-roberta-base', 'BATCH_SIZE': 8, 'EPOCHS': 8, 'LEARNING_RATE': 4.2896922812818176e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for fr language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in fr language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-fr-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='xlm-roberta-base', batch_size=8, epochs=8, learning_rate=4.2896922812818176e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [600/600 06:47, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.958700</td>\n",
       "      <td>0.814152</td>\n",
       "      <td>0.377078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>0.809080</td>\n",
       "      <td>0.371063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.697800</td>\n",
       "      <td>0.776382</td>\n",
       "      <td>0.383744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.608700</td>\n",
       "      <td>0.910088</td>\n",
       "      <td>0.386629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.542200</td>\n",
       "      <td>0.948769</td>\n",
       "      <td>0.383281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.497900</td>\n",
       "      <td>1.123249</td>\n",
       "      <td>0.391582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.408000</td>\n",
       "      <td>1.183037</td>\n",
       "      <td>0.391515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.378700</td>\n",
       "      <td>1.258636</td>\n",
       "      <td>0.394022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-fr-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "xlm-roberta-base trained on fr languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.38171291116580885\n",
      "acc: 0.735\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.69      0.75      0.72        79\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         4\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.77      0.85      0.81       103\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00        14\n",
      "\n",
      "                                      accuracy                           0.73       200\n",
      "                                     macro avg       0.36      0.40      0.38       200\n",
      "                                  weighted avg       0.67      0.73      0.70       200\n",
      "\n",
      "[[0.74683544 0.         0.25316456 0.        ]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.14563107 0.         0.85436893 0.        ]\n",
      " [0.64285714 0.         0.35714286 0.        ]]\n",
      "Total execution time to finetune xlm-roberta-base on fr language(s) is 417.7788071632385\n",
      "\n",
      "Train using data from it languages\n",
      "{'lang': 'it', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'cardiffnlp/twitter-xlm-roberta-base', 'batch_size': 8, 'epochs': 6, 'learning_rate': 2.121329094057246e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with cardiffnlp/twitter-xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'it', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'cardiffnlp/twitter-xlm-roberta-base', 'BATCH_SIZE': 8, 'EPOCHS': 6, 'LEARNING_RATE': 2.121329094057246e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for it language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in it language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-it-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='cardiffnlp/twitter-xlm-roberta-base', batch_size=8, epochs=6, learning_rate=2.121329094057246e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/450 05:02, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.597000</td>\n",
       "      <td>0.500450</td>\n",
       "      <td>0.360870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.457900</td>\n",
       "      <td>0.508427</td>\n",
       "      <td>0.368859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.393500</td>\n",
       "      <td>0.620608</td>\n",
       "      <td>0.377941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.677238</td>\n",
       "      <td>0.374489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.261300</td>\n",
       "      <td>0.692259</td>\n",
       "      <td>0.368137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.239400</td>\n",
       "      <td>0.709148</td>\n",
       "      <td>0.370205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/twitter-xlm-roberta-base-it-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "twitter-xlm-roberta-base trained on it languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.39732142857142855\n",
      "acc: 0.885\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.58      0.72      0.64        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.94      0.95      0.95       167\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00         6\n",
      "\n",
      "                                      accuracy                           0.89       200\n",
      "                                     macro avg       0.38      0.42      0.40       200\n",
      "                                  weighted avg       0.86      0.89      0.87       200\n",
      "\n",
      "[[0.72       0.         0.28       0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.04790419 0.         0.95209581 0.        ]\n",
      " [0.5        0.         0.5        0.        ]]\n",
      "Total execution time to finetune twitter-xlm-roberta-base on it language(s) is 314.3795289993286\n",
      "{'lang': 'it', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'jhu-clsp/bernice', 'batch_size': 32, 'epochs': 7, 'learning_rate': 2.7820794319855572e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with jhu-clsp/bernice\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'it', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'jhu-clsp/bernice', 'BATCH_SIZE': 32, 'EPOCHS': 7, 'LEARNING_RATE': 2.7820794319855572e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for it language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in it language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-it-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='jhu-clsp/bernice', batch_size=32, epochs=7, learning_rate=2.7820794319855572e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at jhu-clsp/bernice and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='95' max='133' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 95/133 05:14 < 02:08, 0.30 it/s, Epoch 5/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.659200</td>\n",
       "      <td>0.496709</td>\n",
       "      <td>0.226776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.438000</td>\n",
       "      <td>0.458730</td>\n",
       "      <td>0.383921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.352600</td>\n",
       "      <td>0.490001</td>\n",
       "      <td>0.375658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.311900</td>\n",
       "      <td>0.476418</td>\n",
       "      <td>0.377612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.257100</td>\n",
       "      <td>0.539293</td>\n",
       "      <td>0.375658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bernice-it-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bernice trained on it languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.39261450799912334\n",
      "acc: 0.88\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.59      0.68      0.63        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.93      0.95      0.94       167\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00         6\n",
      "\n",
      "                                      accuracy                           0.88       200\n",
      "                                     macro avg       0.38      0.41      0.39       200\n",
      "                                  weighted avg       0.85      0.88      0.86       200\n",
      "\n",
      "[[0.68       0.         0.32       0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.04790419 0.         0.95209581 0.        ]\n",
      " [0.33333333 0.         0.66666667 0.        ]]\n",
      "Total execution time to finetune bernice on it language(s) is 325.83008646965027\n",
      "{'lang': 'it', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'bert-base-multilingual-uncased', 'batch_size': 16, 'epochs': 9, 'learning_rate': 1.5020978833449689e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with bert-base-multilingual-uncased\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'it', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'bert-base-multilingual-uncased', 'BATCH_SIZE': 16, 'EPOCHS': 9, 'LEARNING_RATE': 1.5020978833449689e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for it language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in it language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-it-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='bert-base-multilingual-uncased', batch_size=16, epochs=9, learning_rate=1.5020978833449689e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='228' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [228/342 03:32 < 01:47, 1.07 it/s, Epoch 6/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.526748</td>\n",
       "      <td>0.226776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.436900</td>\n",
       "      <td>0.480151</td>\n",
       "      <td>0.334034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.343200</td>\n",
       "      <td>0.479292</td>\n",
       "      <td>0.358618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.475527</td>\n",
       "      <td>0.356988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.202400</td>\n",
       "      <td>0.579857</td>\n",
       "      <td>0.347601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.157100</td>\n",
       "      <td>0.672185</td>\n",
       "      <td>0.343505</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/bert-base-multilingual-uncased-it-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "bert-base-multilingual-uncased trained on it languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.35294117647058826\n",
      "acc: 0.84\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.48      0.52      0.50        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.90      0.93      0.91       167\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00         6\n",
      "\n",
      "                                      accuracy                           0.84       200\n",
      "                                     macro avg       0.34      0.36      0.35       200\n",
      "                                  weighted avg       0.81      0.84      0.82       200\n",
      "\n",
      "[[0.52       0.         0.48       0.        ]\n",
      " [0.5        0.         0.5        0.        ]\n",
      " [0.07185629 0.         0.92814371 0.        ]\n",
      " [0.16666667 0.         0.83333333 0.        ]]\n",
      "Total execution time to finetune bert-base-multilingual-uncased on it language(s) is 220.88813662528992\n",
      "{'lang': 'it', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'microsoft/mdeberta-v3-base', 'batch_size': 32, 'epochs': 4, 'learning_rate': 3.399329304887933e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with microsoft/mdeberta-v3-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'it', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'microsoft/mdeberta-v3-base', 'BATCH_SIZE': 32, 'EPOCHS': 4, 'LEARNING_RATE': 3.399329304887933e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for it language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in it language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-it-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='microsoft/mdeberta-v3-base', batch_size=32, epochs=4, learning_rate=3.399329304887933e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/mdeberta-v3-base and are newly initialized: ['pooler.dense.weight', 'pooler.dense.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='76' max='76' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [76/76 04:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>0.579679</td>\n",
       "      <td>0.226776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.519700</td>\n",
       "      <td>0.457521</td>\n",
       "      <td>0.278532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.415625</td>\n",
       "      <td>0.383138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.338500</td>\n",
       "      <td>0.445562</td>\n",
       "      <td>0.379199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/mdeberta-v3-base-it-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "mdeberta-v3-base trained on it languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.3607547917388936\n",
      "acc: 0.84\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.44      0.64      0.52        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.93      0.91      0.92       167\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00         6\n",
      "\n",
      "                                      accuracy                           0.84       200\n",
      "                                     macro avg       0.34      0.39      0.36       200\n",
      "                                  weighted avg       0.83      0.84      0.83       200\n",
      "\n",
      "[[0.64       0.         0.36       0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.08982036 0.         0.91017964 0.        ]\n",
      " [0.5        0.         0.5        0.        ]]\n",
      "Total execution time to finetune mdeberta-v3-base on it language(s) is 263.91340589523315\n",
      "{'lang': 'it', 'split': '0.6,0.2,0.2', 'n_labels': 4, 'max_len': 128, 'model_checkpoint': 'xlm-roberta-base', 'batch_size': 8, 'epochs': 8, 'learning_rate': 1.089678819474072e-05, 'target_names': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n",
      "Distribution of data in train, validation and test splits: 600, 200, 200\n",
      "Working with xlm-roberta-base\n",
      "\n",
      "Final configurations for processing training + validation data\n",
      "{'LANG': 'it', 'SPLIT': '0.6,0.2,0.2', 'N_LABELS': 4, 'MAX_LEN': 128, 'MODEL_CHECKPOINT': 'xlm-roberta-base', 'BATCH_SIZE': 8, 'EPOCHS': 8, 'LEARNING_RATE': 1.089678819474072e-05, 'TARGET_NAMES': ['1. Likely ILI infection', '2. Likely COVID-19 Infection (after 2020 only)', '3. Not Related to ILI or COVID-19 Infection', '4. Ambiguous/Unsure']}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of encoded features: torch.Size([4400, 128])\n",
      "Encoding contains: ['input_ids', 'token_type_ids', 'attention_mask']\n",
      "Distribution of data splits for it language is (600, 4), (200, 4), (200, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 classes in it language\n",
      "Model to be saved in /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-it-finetuned\n",
      "\n",
      "Training model using with configurations:\n",
      "namespace(max_len=128, model_checkpoint='xlm-roberta-base', batch_size=8, epochs=8, learning_rate=1.089678819474072e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='450' max='600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [450/600 06:54 < 02:18, 1.08 it/s, Epoch 6/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.780600</td>\n",
       "      <td>0.571764</td>\n",
       "      <td>0.226776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.532600</td>\n",
       "      <td>0.449375</td>\n",
       "      <td>0.226776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>0.431033</td>\n",
       "      <td>0.386957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.389600</td>\n",
       "      <td>0.496138</td>\n",
       "      <td>0.383138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.551049</td>\n",
       "      <td>0.371672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.287000</td>\n",
       "      <td>0.620056</td>\n",
       "      <td>0.379412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/evalnew/testset0.6_0.2_0.2/models/xlm-roberta-base-it-finetuned\n",
      "\n",
      "Getting Predictions on Test dataset\n",
      "\n",
      "xlm-roberta-base trained on it languages\n",
      "free space by deleting: /gaueko0/users/nmishra/multiling_fludetection/models\n",
      "Number of labels in target_names is 4\n",
      "f1: 0.37454778204486006\n",
      "acc: 0.865\n",
      "                                                precision    recall  f1-score   support\n",
      "\n",
      "                       1. Likely ILI infection       0.54      0.60      0.57        25\n",
      "2. Likely COVID-19 Infection (after 2020 only)       0.00      0.00      0.00         2\n",
      "   3. Not Related to ILI or COVID-19 Infection       0.92      0.95      0.93       167\n",
      "                           4. Ambiguous/Unsure       0.00      0.00      0.00         6\n",
      "\n",
      "                                      accuracy                           0.86       200\n",
      "                                     macro avg       0.36      0.39      0.37       200\n",
      "                                  weighted avg       0.83      0.86      0.85       200\n",
      "\n",
      "[[0.6        0.         0.4        0.        ]\n",
      " [1.         0.         0.         0.        ]\n",
      " [0.05389222 0.         0.94610778 0.        ]\n",
      " [0.33333333 0.         0.66666667 0.        ]]\n",
      "Total execution time to finetune xlm-roberta-base on it language(s) is 425.11832666397095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/gaueko0/users/nmishra/niti_venv/trumoi-transformers-4.20/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# read data split index\n",
    "SPLITS = params['split'].unique()\n",
    "for split in SPLITS:\n",
    "    dirname = f\"testset{split.replace(',','_')}\"\n",
    "    split_path = OUT_PATH.joinpath(dirname)\n",
    "    print(f\"Reading data split index from: {split_path}\")\n",
    "    with open(split_path.joinpath('split_idx.json'), 'r') as f:\n",
    "        split_idx = json.load(f) \n",
    "   \n",
    "    for lang, lang_params in params.groupby('lang'):  \n",
    "        # if lang=='all' or lang=='en':\n",
    "        # get split idx \n",
    "        if lang=='all':\n",
    "            # for all languages in the list\n",
    "            print(f\"\\nTrain using data from all languages\")\n",
    "            languages = [i for i in params['lang'].unique() if i!= 'all']\n",
    "            lang_split_idx = {i:split_idx[i] for i in languages}\n",
    "            lang_eval = True\n",
    "        else:\n",
    "            # for each language in the list\n",
    "            print(f\"\\nTrain using data from {lang} languages\")\n",
    "            lang_split_idx = {}\n",
    "            lang_split_idx[lang] = split_idx[lang]\n",
    "            lang_eval = False\n",
    "        \n",
    "        # get training parameters for models and train\n",
    "        training_params = lang_params.to_dict(orient='records')\n",
    "        for config in training_params:\n",
    "            config['target_names'] = target_names\n",
    "            print(config)\n",
    "            mlm_evaluation(lang_split_idx, tweets, config, split_path, cache_path, lang, lang_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b81d987e-bc43-4e26-8b0d-92ca4b903be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # read data split index\n",
    "# splits = params['split'].unique()\n",
    "# for split in splits:\n",
    "    \n",
    "#     cache_path = OUT_PATH.parent.joinpath('.cache')\n",
    "#     cache_path.mkdir(parents=True, exist_ok=True)\n",
    "#     print(f\"Cache in {cache_path}\")\n",
    "\n",
    "#     dirname = f\"testset{'_'.join([str(i) for i in split])}\"\n",
    "#     split_path = OUT_PATH.joinpath(dirname)\n",
    "#     print(f\"Reading data split index from: {split_path}\")\n",
    "#     with open(split_path.joinpath('split_idx.json'), 'r') as f:\n",
    "#         split_idx = json.load(f) \n",
    "        \n",
    "#     # determine languages for which to get split index\n",
    "#     if params['LANG']=='all':\n",
    "#         languages = [i for i in split_idx]\n",
    "#     else:\n",
    "#         languages = [i for i in split_idx if i in params['LANG'].split(',')]\n",
    "    \n",
    "#     # # train on all languages and then on each language\n",
    "#     # lang_split_idx = {i:split_idx[i] for i in languages}\n",
    "#     # print(f\"Training data used for {params['LANG']} languages\")\n",
    "#     # mlm_evaluation(lang_split_idx, tweets, params, split_path, dirname, params['LANG'], cache_path)\n",
    "    \n",
    "#     for lang_to_train in languages:\n",
    "#         if lang_to_train=='es': #or lang_to_train=='it':\n",
    "#             print(f\"\\nTraining data used for {lang_to_train} language\")\n",
    "#             lang_split_idx = {}\n",
    "#             lang_split_idx[lang_to_train] = split_idx[lang_to_train]\n",
    "#             mlm_evaluation(lang_split_idx, tweets, params, split_path, dirname, lang_to_train, cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaeed52b-031a-4f86-aee8-2096dade7030",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # read data split index\n",
    "# for split in params['SPLITS'][:1]:\n",
    "    \n",
    "#     cache_path = OUT_PATH.parent.joinpath('.cache')\n",
    "#     cache_path.mkdir(parents=True, exist_ok=True)\n",
    "#     print(f\"Cache in {cache_path}\")\n",
    "\n",
    "#     dirname = f\"testset{'_'.join([str(i) for i in split])}\"\n",
    "#     split_path = OUT_PATH.joinpath(dirname)\n",
    "#     print(f\"Reading data split index from: {split_path}\")\n",
    "#     with open(split_path.joinpath('split_idx.json'), 'r') as f:\n",
    "#         split_idx = json.load(f) \n",
    "        \n",
    "#     # determine languages for which to get split index\n",
    "#     if params['LANG']=='all':\n",
    "#         languages = [i for i in split_idx]\n",
    "#     else:\n",
    "#         languages = [i for i in split_idx if i in params['LANG'].split(',')]\n",
    "    \n",
    "#     # train on all languages and then on each language\n",
    "#     lang_split_idx = {i:split_idx[i] for i in languages}\n",
    "#     print(f\"Training data used for {params['LANG']} languages\")\n",
    "#     # mlm_evaluation(lang_split_idx, tweets, params, split_path, dirname, params['LANG'], cache_path)\n",
    "    \n",
    "#     for lang_to_train in languages:\n",
    "#         print(f\"\\nTraining data used for {lang_to_train} language\")\n",
    "#         lang_split_idx = {}\n",
    "#         lang_split_idx[lang_to_train] = split_idx[lang_to_train]\n",
    "#         mlm_evaluation(lang_split_idx, tweets, params, split_path, dirname, lang_to_train, cache_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ed7447-b0ec-439e-ae0d-89a1ef561bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipykernel ILI Test",
   "language": "python",
   "name": "ipykernel-ili-test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

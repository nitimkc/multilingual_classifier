{
    "BATCH_SIZE" : 16,
    "EPOCHS" : 10, 
    "MAX_LEN" : 128,
    "SPLITS" : [[0.6, 0.2, 0.2]],
    "LANG" :   "all",
    "MODELS" : 
    {
        "all":
        [
            {
                "MODEL_CHECKPOINT" : "cardiffnlp/twitter-xlm-roberta-base",
                "LEARNING_RATE" : 3.571430010972717e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 7
            },{
                "MODEL_CHECKPOINT" : "jhu-clsp/bernice",
                "LEARNING_RATE" : 1.9960876362570808e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 6
            },{
                "MODEL_CHECKPOINT" : "bert-base-multilingual-uncased",
                "LEARNING_RATE" : 4.714003352774175e-05,
                "BATCH_SIZE" : 32
            },{
                "MODEL_CHECKPOINT" : "microsoft/mdeberta-v3-base",
                "LEARNING_RATE" : 2.2015563091912367e-05,
                "BATCH_SIZE" : 16
            },{
                "MODEL_CHECKPOINT" : "xlm-roberta-base",
                "LEARNING_RATE" : 4.129082702898313e-05,
                "BATCH_SIZE" : 16,
                "EPOCHS" : 8
            }
        ],
        "en":
        [
            { 
                "MODEL_CHECKPOINT" : "cardiffnlp/twitter-xlm-roberta-base",
                "LEARNING_RATE" :  0.00014874839857103098,
                "BATCH_SIZE" : 32,
                "EPOCHS" : 6
            },{
                "MODEL_CHECKPOINT" : "jhu-clsp/bernice",
                "LEARNING_RATE" : 0.00010386488825327678,
                "BATCH_SIZE" : 16,
                "EPOCHS" : 2
            },{
                "MODEL_CHECKPOINT" : "bert-base-multilingual-uncased",
                "LEARNING_RATE" : 0.00010481405054288424,
                "BATCH_SIZE" : 32,
                "EPOCHS" : 7
            },{
                "MODEL_CHECKPOINT" : "microsoft/mdeberta-v3-base",
                "LEARNING_RATE" : 6.214702150620456e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 7
            },{
                "MODEL_CHECKPOINT" : "xlm-roberta-base",
                "LEARNING_RATE" :  7.64366123017573e-05,
                "BATCH_SIZE" : 16,
                "EPOCHS" : 9
            }
        ],
        "fr":
        [
            {
                "MODEL_CHECKPOINT" : "cardiffnlp/twitter-xlm-roberta-base",
                "LEARNING_RATE" : 2.5967668474332716e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 4,
                "MAX_LEN" : 256
            },{
                "MODEL_CHECKPOINT" : "jhu-clsp/bernice",
                "LEARNING_RATE" :  8.106216723781869e-05,
                "BATCH_SIZE" : 16,
                "EPOCHS" : 6
            },{
                "MODEL_CHECKPOINT" : "bert-base-multilingual-uncased",
                "LEARNING_RATE" : 1.4333262623697738e-05,
                "BATCH_SIZE" : 8
            },{
                "MODEL_CHECKPOINT" : "microsoft/mdeberta-v3-base",
                "LEARNING_RATE" :  9.84639301079326e-05,
                "BATCH_SIZE" : 16,
                "EPOCHS" : 6
            },{
                "MODEL_CHECKPOINT" : "xlm-roberta-base",
                "LEARNING_RATE" : 4.2896922812818176e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 8
            }
        ],
        "es":
        [
            {
                "MODEL_CHECKPOINT" : "cardiffnlp/twitter-xlm-roberta-base",
                "LEARNING_RATE" : 7.96269320820549e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 4
            },{
                "MODEL_CHECKPOINT" : "jhu-clsp/bernice",
                "LEARNING_RATE" :  7.48302766200615e-05,
                "BATCH_SIZE" : 32
            },{
                "MODEL_CHECKPOINT" : "bert-base-multilingual-uncased",
                "LEARNING_RATE" : 2.7742632399963146e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 6,
                "MAX_LEN" : 256
            },{
                "MODEL_CHECKPOINT" : "microsoft/mdeberta-v3-base",
                "LEARNING_RATE" : 3.4072290216883676e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 6
            },{
                "MODEL_CHECKPOINT" : "xlm-roberta-base",
                "LEARNING_RATE" : 3.032823977759674e-05,
                "BATCH_SIZE" : 16
            }
        ],
        "it":
        [
            {
                "MODEL_CHECKPOINT" : "cardiffnlp/twitter-xlm-roberta-base",
                "LEARNING_RATE" : 2.121329094057246e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 6
            },{
                "MODEL_CHECKPOINT" : "jhu-clsp/bernice",
                "LEARNING_RATE" : 2.7820794319855575e-05,
                "BATCH_SIZE" : 32,
                "EPOCHS" : 7
            },{
                "MODEL_CHECKPOINT" : "bert-base-multilingual-uncased",
                "LEARNING_RATE" : 1.5020978833449689e-05,
                "BATCH_SIZE" : 16,
                "EPOCHS" : 9
            },{
                "MODEL_CHECKPOINT" : "microsoft/mdeberta-v3-base",
                "LEARNING_RATE" : 3.399329304887933e-05,
                "BATCH_SIZE" : 32,
                "EPOCHS" : 4
            },{
                "MODEL_CHECKPOINT" : "xlm-roberta-base",
                "LEARNING_RATE" : 1.089678819474072e-05,
                "BATCH_SIZE" : 8,
                "EPOCHS" : 8
            }
        ],
        "de":
        [
            {
                "MODEL_CHECKPOINT" : "cardiffnlp/twitter-xlm-roberta-base",
                "LEARNING_RATE" :  6.303128537215267e-05,
                "BATCH_SIZE" : 32,
                "EPOCHS" : 6
            },{
                "MODEL_CHECKPOINT" : "jhu-clsp/bernice",
                "LEARNING_RATE" :  1.931835053890701e-05,
                "BATCH_SIZE" : 32,
                "EPOCHS" : 5
            },{
                "MODEL_CHECKPOINT" : "bert-base-multilingual-uncased",
                "LEARNING_RATE" :  1.760419522770641e-05,
                "BATCH_SIZE" : 16,
                "EPOCHS" : 3
            },{
                "MODEL_CHECKPOINT" : "microsoft/mdeberta-v3-base",
                "LEARNING_RATE" :  1.846007640647933e-05,
                "BATCH_SIZE" : 32,
                "EPOCHS" : 6
            },{
                "MODEL_CHECKPOINT" : "xlm-roberta-base",
                "LEARNING_RATE" : 2.216664432392652e-05,
                "BATCH_SIZE" : 32,
                "EPOCHS" : 6
            }
        ]  
    }  
}
